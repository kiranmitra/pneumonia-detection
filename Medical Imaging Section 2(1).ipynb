{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Medical Imaging Section 2.ipynb","provenance":[{"file_id":"1EUH7Gjb2hAQvvIiMgVjA5poGq4LsfOk7","timestamp":1604159805046}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"T4sLmjIuDpmY"},"source":["![](https://storage.googleapis.com/kaggle-competitions/kaggle/10338/logos/header.png)"]},{"cell_type":"code","metadata":{"id":"aSeClkWgIORK","executionInfo":{"status":"ok","timestamp":1605382440800,"user_tz":480,"elapsed":7146,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"97adb056-7a46-4340-88b8-f03f4a752801","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n","def augment(data, augmenter):\n","  if len(data.shape) == 3:\n","    return augmenter.augment_image(data)\n","  if len(data.shape) == 4:\n","    return augmenter.augment_images(data)\n","    \n","def rotate(data, rotate):\n","  fun = augmenters.Affine(rotate = rotate)\n","  return augment(data, fun)\n","\n","def shear(data, shear):\n","  fun = augmenters.Affine(shear = shear)\n","  return augment(data, fun)\n","\n","def scale(data, scale):\n","  fun = augmenters.Affine(scale = shear)\n","  return augment(data, fun)\n","  \n","def flip_left_right(data):\n","  fun = augmenters.Fliplr()\n","  return augment(data, fun)\n","\n","def flip_up_down(data):\n","  fun = augmenters.Flipud()\n","  return augment(data, fun)\n","\n","def remove_color(data, channel):\n","  new_data = data.copy()\n","  if len(data.shape) == 3:\n","    new_data[:,:,channel] = 0\n","    return new_data\n","  if len(data.shape) == 4:\n","    new_data[:,:,:,channel] = 0\n","    return new_data\n","  \n","class pkg:\n","  #### DOWNLOADING AND LOADING DATA\n","  def get_metadata(metadata_path, which_splits = ['train', 'test']):  \n","    '''returns metadata dataframe which contains columns of:\n","       * index: index of data into numpy data\n","       * class: class of image\n","       * split: which dataset split is this a part of? \n","    '''\n","    metadata = pd.read_csv(metadata_path)\n","    keep_idx = metadata['split'].isin(which_splits)\n","    return metadata[keep_idx]\n","\n","  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n","    '''\n","    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n","    flattens if flatten option is True \n","    '''\n","    sub_df = metadata[metadata['split'].isin([split_name])]\n","    index  = sub_df['index'].values\n","    labels = sub_df['class'].values\n","    data = all_data[index,:]\n","    if flatten:\n","      data = data.reshape([-1, np.product(image_shape)])\n","    return data, labels\n","\n","  def get_train_data(flatten, all_data, metadata, image_shape):\n","    return get_data_split('train', flatten, all_data, metadata, image_shape)\n","\n","  def get_test_data(flatten, all_data, metadata, image_shape):\n","    return get_data_split('test', flatten, all_data, metadata, image_shape)\n","\n","  def get_field_data(flatten, all_data, metadata, image_shape):\n","    return get_data_split('field', flatten, all_data, metadata, image_shape)\n","  \n","class helpers:\n","  #### PLOTTING\n","  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n","    '''\n","    if data is a single image, display that image\n","\n","    if data is a 4d stack of images, display that image\n","    '''\n","    num_dims   = len(data.shape)\n","    num_labels = len(labels)\n","\n","    # reshape data if necessary\n","    if num_dims == 1:\n","      data = data.reshape(target_shape)\n","    if num_dims == 2:\n","      data = data.reshape(np.vstack[-1, image_shape])\n","    num_dims   = len(data.shape)\n","\n","    # check if single or multiple images\n","    if num_dims == 3:\n","      if num_labels > 1:\n","        print('Multiple labels does not make sense for single image.')\n","        return\n","\n","      label = labels      \n","      if num_labels == 0:\n","        label = ''\n","      image = data\n","\n","    if num_dims == 4:\n","      image = data[index, :]\n","      label = labels[index]\n","\n","    # plot image of interest\n","    print('Label: %s'%label)\n","    plt.imshow(image)\n","    plt.show()\n","\n","  #### QUERYING AND COMBINING DATA\n","  def get_misclassified_data(data, labels, predictions):\n","    '''\n","    Gets the data and labels that are misclassified in a classification task\n","    Returns:\n","    -missed_data\n","    -missed_labels\n","    -predicted_labels (corresponding to missed_labels)\n","    -missed_index (indices of items in original dataset)\n","    '''\n","    missed_index     = np.where(np.abs(predictions.squeeze() - labels.squeeze()) > 0)[0]\n","    missed_labels    = labels[missed_index]\n","    missed_data      = data[missed_index,:]\n","    predicted_labels = predictions[missed_index]\n","    return missed_data, missed_labels, predicted_labels, missed_index\n","\n","  def combine_data(data_list, labels_list):\n","    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n","\n","  def model_to_string(model):\n","    import re\n","    stringlist = []\n","    model.summary(print_fn=lambda x: stringlist.append(x))\n","    sms = \"\\n\".join(stringlist)\n","    sms = re.sub('_\\d\\d\\d','', sms)\n","    sms = re.sub('_\\d\\d','', sms)\n","    sms = re.sub('_\\d','', sms)  \n","    return sms\n","\n","  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n","    # i'm sorry for this function's code. i am so sorry. \n","    history = history.history\n","    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n","    history = pd.DataFrame.from_dict(history)\n","\n","    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n","\n","    if not ax:\n","      f, ax = plt.subplots(1,1)\n","    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n","    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n","    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n","    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n","    ax.legend(loc = 1)    \n","    ax.set_ylim([0.4, 1])\n","\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel('Accuracy (Fraction)')\n","    \n","    plt.show()\n","\n","class models:\n","  def DenseClassifier(hidden_layer_sizes, nn_params):\n","    model = Sequential()\n","    model.add(Flatten(input_shape = nn_params['input_shape']))\n","    for ilayer in hidden_layer_sizes:\n","      model.add(Dense(ilayer, activation = 'relu'))\n","    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n","    model.compile(loss=nn_params['loss'],\n","                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n","                  metrics=['accuracy'])\n","    return model\n","\n","  def CNNClassifier(num_hidden_layers, nn_params):\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    for i in range(num_hidden_layers-1):\n","        model.add(Conv2D(32, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten()) \n","\n","    model.add(Dense(units = 128, activation = 'relu'))\n","\n","    model.add(Dense(units = 64, activation = 'relu'))\n","\n","\n","    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n","\n","    # initiate RMSprop optimizer\n","    opt = keras.optimizers.RMSprop(lr=1e-4, decay=1e-6)\n","\n","    # Let's train the model using RMSprop\n","    model.compile(loss=nn_params['loss'],\n","                  optimizer=opt,\n","                  metrics=['accuracy'])    \n","    return model\n","\n","  def TransferClassifier(name, nn_params, trainable = True):\n","    expert_dict = {'VGG16': VGG16, \n","                   'VGG19': VGG19,\n","                   'ResNet50':ResNet50,\n","                   'DenseNet121':DenseNet121}\n","\n","    expert_conv = expert_dict[name](weights = 'imagenet', \n","                                              include_top = False, \n","                                              input_shape = nn_params['input_shape'])\n","    for layer in expert_conv.layers:\n","      layer.trainable = trainable\n","      \n","    expert_model = Sequential()\n","    expert_model.add(expert_conv)\n","    expert_model.add(GlobalAveragePooling2D())\n","\n","    expert_model.add(Dense(128, activation = 'relu'))\n","    expert_model.add(Dropout(0.3))\n","\n","    expert_model.add(Dense(64, activation = 'relu'))\n","\n","    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n","\n","    expert_model.compile(loss = nn_params['loss'], \n","                  optimizer = optimizers.SGD(lr=1e-4, momentum=0.95), \n","                  metrics=['accuracy'])\n","\n","    return expert_model\n","\n","import gdown\n","import zipfile\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn import model_selection\n","\n","from collections import Counter\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n","from keras.wrappers.scikit_learn import KerasClassifier\n","import keras.optimizers as optimizers\n","from keras.callbacks import ModelCheckpoint\n","\n","from keras.applications import VGG16, VGG19, ResNet50, DenseNet121\n","\n","from imgaug import augmenters \n","\n","### defining project variables\n","# file variables\n","image_data_url       = 'https://drive.google.com/uc?id=1DNEiLAWguswhiLXGyVKsgHIRm1xZggt_'\n","metadata_url         = 'https://drive.google.com/uc?id=1MW3_FU6qc0qT_uG4bzxhtEHy4Jd6dCWb'\n","image_data_path      = './image_data.npy'\n","metadata_path        = './metadata.csv'\n","image_shape          = (64, 64, 3)\n","\n","# neural net parameters\n","nn_params = {}\n","nn_params['input_shape']       = image_shape\n","nn_params['output_neurons']    = 1\n","nn_params['loss']              = 'binary_crossentropy'\n","nn_params['output_activation'] = 'sigmoid'\n","\n","###\n","gdown.download(image_data_url, './image_data.npy', True)\n","gdown.download(metadata_url, './metadata.csv', True)\n","\n","### pre-loading all data of interest\n","_all_data = np.load('image_data.npy')\n","_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n","\n","### preparing definitions\n","# downloading and loading data\n","get_data_split = pkg.get_data_split\n","get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n","get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n","get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n","get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n","\n","# plotting\n","plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n","plot_acc       = lambda history: helpers.plot_acc(history)\n","\n","# querying and combining data\n","model_to_string        = lambda model: helpers.model_to_string(model)\n","get_misclassified_data = helpers.get_misclassified_data;\n","combine_data           = helpers.combine_data;\n","\n","# models with input parameters\n","DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n","CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n","TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n","\n","monitor = ModelCheckpoint('./model.h5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QFfMH3dYX_GM"},"source":["# Milestone 1. Understanding and building Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"l-hvosCRrBGu"},"source":["## Instructor-led Discussion: Steps for Building a NN in Keras"]},{"cell_type":"markdown","metadata":{"id":"SYqvCKWpKfRM"},"source":["### What are neural networks?"]},{"cell_type":"markdown","metadata":{"id":"qA1Rc_u3KoJT"},"source":["Just as we went over last week, neural networks look something like this: \n","![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n"]},{"cell_type":"markdown","metadata":{"id":"3Q9S6SDcM8N9"},"source":["Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction. Let's get a bit more concrete with this..."]},{"cell_type":"markdown","metadata":{"id":"E--8mjToZYBp"},"source":["To build neural networks in Python, we use the packages known as `tensorflow` and `keras`. Let's learn how to build and use these networks!"]},{"cell_type":"markdown","metadata":{"id":"G8PrEOTbhgNN"},"source":["Tensorflow calls the various machine learning algorithms that it uses 'models'.  These 'models' are 'learning machines.''\n","\n","1. We **teach** models by **training** them on **data**. \n","2. We **use** models to **predict** things. \n"]},{"cell_type":"markdown","metadata":{"id":"cPOqTta1sb6e"},"source":["Before we train the model or use it to predict something, we have to **create** the model. \n","\n","With the following code, we create a model that corresponds to our multineuron network for the housing problem above:"]},{"cell_type":"code","metadata":{"id":"cqFAnQCxsgRm","executionInfo":{"status":"ok","timestamp":1605382448123,"user_tz":480,"elapsed":604,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["# grab tools from our tensorflow and keras toolboxes!\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import optimizers"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yus22AQpsqMH","executionInfo":{"status":"ok","timestamp":1605375743766,"user_tz":480,"elapsed":5974,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["# create our model by specifying and compiling it\n","model = Sequential()\n","model.add(Dense(4, input_shape=(3,),activation = 'relu'))\n","model.add(Dense(1, activation = 'linear'))\n","model.compile(loss='mean_squared_error',\n","                optimizer='adam',\n","                metrics=['mean_squared_error'])"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LG3k7_983L1s"},"source":["The things you'll want to pay most attention to as we go over how to build networks are: \n","1. The number of neurons\n","2. The activation of the neurons\n","3. The losses and metrics\n","\n","Everything else will work with the default settings!"]},{"cell_type":"markdown","metadata":{"id":"781M4IyhssuA"},"source":["Let's walk though what each of these lines of code means!\n","\n","**1. Specify model**\n","\n","```\n","model = Sequential()\n","```\n","In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n","\n","\n","**2. Add layers to the network**\n","```\n","model.add(Dense(4,input_shape = (3,), activation = 'sigmoid'))\n","```\n","In this code, we `add` a `layer` of neurons to our network. \n","\n","This layers consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n","\n","We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'sigmoid'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers. \n","\n","```\n","model.add(Dense(1, activation = 'linear'))\n","```\n","This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n","\n","**3. Turn the model on by compiling it** \n","\n","After having built the network, we want to train and use it, so we have to 'turn it on' and 'compile' it. To turn it on, we have to specify at the very least, a loss, an optimizer, and some ways of evaluating the model (metrics). Don't worry too much about what this means! Just know that this is necessary. \n","\n","```\n","model.compile(loss='mean_squared_error',\n","optimizer = 'adam',\n","metrics = ['mean_squared_error'])\n","  ```"]},{"cell_type":"markdown","metadata":{"id":"toYjQUOVtKDT"},"source":["Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`. \n","\n","```\n","model.fit(x, y)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"-aozkfBxtWa7"},"source":["To use the model, you can use it to predict something with:\n","```\n","y = model.predict_classes(x)\n","```\n","\n","You can actually use the model before you even train it! It just won't perform very well. "]},{"cell_type":"markdown","metadata":{"id":"fq4G0hDwZKnM"},"source":["## Exercise (Coding): A 2-Layer Model"]},{"cell_type":"markdown","metadata":{"id":"Bj-Pt3wGCXRu"},"source":["\n","We're going to build this model: \n","\n","![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"]},{"cell_type":"markdown","metadata":{"id":"H-6WGeedvTCS"},"source":["This network can be described as: \n","* Input Layer: 3\n","* Layer 1 (Hidden): 4 neurons that are activated by `'relu'`\n","* Layer 2 (Output): 2 neurons that are activated by `'linear'`\n","\n","\n","We also want to compile the model with\n","`loss = 'binary_crossentropy'`"]},{"cell_type":"code","metadata":{"id":"d4rDgysgFtsC","executionInfo":{"status":"ok","timestamp":1605382444765,"user_tz":480,"elapsed":576,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["# grab tools from our tensorflow and keras toolboxes!\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import optimizers"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zgA-wPfvCyK"},"source":["# Fill in the blanks with your group!\n","### YOUR CODE HERE:\n","model_1 = Sequential()\n","model_1.add(Dense(4, input_shape = (3,), activation = 'relu'))\n","model_1.add(Dense(2, activation = 'linear'))\n","model_1.compile(loss='binary_cross_entropy',\n","                optimizer = 'adam', \n","                metrics = ['accuracy'])\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IH2UGOK4vuZ4","cellView":"form","executionInfo":{"status":"ok","timestamp":1604160866278,"user_tz":420,"elapsed":456,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"8ff5d787-a7e7-4262-c1b9-70e1d06f3580","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@title Run this to test if your model is right!\n","model_1_answer = Sequential()\n","model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n","model_1_answer.add(Dense(2, activation = 'softmax'))\n","model_1_answer.compile(loss='categorical_crossentropy',\n","optimizer = 'adam', \n","metrics = ['accuracy'])\n","\n","if model_to_string(model_1) == model_to_string(model_1_answer):\n","  print('Good job! Your model worked')\n","else: \n","  print('Please check your code again!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Good job! Your model worked\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g9CmrRkgT5ZS"},"source":["# Milestone 2. Exploring Neural Networks\n","## Instructor-led Discussion: Inputs and Outputs for our data"]},{"cell_type":"markdown","metadata":{"id":"PD3Z0QamJF68"},"source":["\n","In our problem, we are given `images` of shape `(64,64,3)`, each assigned a label PNEUMONIA or HEALTHY. We want to identify the key things that we need to design our network. \n","\n","In your group, discuss: \n","\n","* What are our inputs?\n","* What is/are our outputs?\n","\n","How could this look in a neural network diagram?\n","\n","**Make a 3-layer (at least) neural network that works for this problem.**\n","\n","**One of you will show the neural network to the group when you're done.**"]},{"cell_type":"markdown","metadata":{"id":"S0xP2sDhOf4M"},"source":["## Activity 2a. Challenging pneumonia with our models"]},{"cell_type":"markdown","metadata":{"id":"P7OiMG9WXrT6"},"source":["### Exercise (Coding) "]},{"cell_type":"markdown","metadata":{"id":"47bngTjCT_pM"},"source":["Today, we started with simple 'fully connected' neural networks that are perceptrons. There are other types of neural networks that we can use, however. \n","\n","We also want to try 'Convolutional Neural Networks'. Convolutional neural networks are networks that process images much like our visual system does -- by using this technique called 'convolutions'. We won't go too much into the details here or how it's implemented in tensorflow. If you'd like more details, you can try the optional activity out below!\n","\n","Otherwise, we provide tensorflow/keras wrappers around both Multilayer Perceptrons and Convolutional Neural Networks\n","### Creating Models\n","\n","To create our multilayer perceptrons with our wrapper:\n","```\n","dense = DenseClassifier(hidden_layer_sizes = (2,2))\n","```\n","* hidden_layer_sizes: the number of neurons in each hidden layer\n","* epochs: the number of times that our network trains on the whole training manual\n","\n","\n","To create a convolution neural network:\n","```\n","cnn = CNNClassifier(num_hidden_layers = 3)\n","```\n","* num_hidden_layers: the number of hidden layers \n","\n","### Fitting and Scoring\n","\n","There are default parameters to `.fit` you can call:\n","\n","```\n","model.fit(train_data, train_labels, epochs = 100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","```\n","\n","The `shuffle` parameter is important for shuffling the training data before each epoch. The `monitor` callback is used to get a view on internal states and statistics of the model during training. Do not change these parameters!\n","\n","To get your testing scores, use \n","\n","```\n","score = model.evaluate(train_data, train_labels, verbose=0)\n","```\n","\n","Then `score[0]` will be test loss and `score[1]` will be test accuracy.\n","\n","### Plotting\n","\n","After fitting your model, you can plot the training and test accuracy over time. First, run your model again with the `.fit` method, except this time you're going to save it as a variable:  \n","\n","```\n","model_history = model.fit(train_data, train_labels, epochs = 100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","```\n","\n","Then, you can look at the plot with with `plot_acc(model_history)`.\n","\n","\n","**Question: What do you observe of the training and test accuracy over the training epochs?** \n","\n","Discuss this with your group and your instructor. "]},{"cell_type":"code","metadata":{"id":"Uq93obZ1VFBc","executionInfo":{"status":"error","timestamp":1605382510976,"user_tz":480,"elapsed":11393,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"b59527e6-3f33-4663-bbcd-5519b5aca289","colab":{"base_uri":"https://localhost:8080/","height":838}},"source":["### YOUR CODE HERE\n","train_data, train_labels = get_train_data()\n","test_data, test_labels = get_test_data()\n","\n","dense = DenseClassifier(hidden_layer_sizes= (64,64))\n","cnn = CNNClassifier(num_hidden_layers = 2)\n","\n","cnn_history = cnn.fit(train_data, train_labels, epochs=100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","dense_history = dense.fit(train_data, train_labels, epochs=100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","\n","cnn_score = cnn.evaluate(train_data, train_labels, verbose = 0)\n","dense_score = dense.evaluate(train_data, train_labels, verbose = 0)\n","\n","print(\"Dense Score is: \" + str(dense_score))\n","print(\"CNN Score is: \" + str(cnn_score))\n","\n","plot_acc(cnn_history)\n","plot_acc(dense_history)\n","\n","### END CODE"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","63/63 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7410WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 1s 10ms/step - loss: 0.5847 - accuracy: 0.7410 - val_loss: 0.5304 - val_accuracy: 0.7825\n","Epoch 2/100\n","63/63 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8755WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8755 - val_loss: 0.3930 - val_accuracy: 0.8650\n","Epoch 3/100\n","55/63 [=========================>....] - ETA: 0s - loss: 0.2815 - accuracy: 0.9028WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.9060 - val_loss: 0.4185 - val_accuracy: 0.7925\n","Epoch 4/100\n","60/63 [===========================>..] - ETA: 0s - loss: 0.2236 - accuracy: 0.9214WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.2235 - accuracy: 0.9210 - val_loss: 0.4175 - val_accuracy: 0.7825\n","Epoch 5/100\n","54/63 [========================>.....] - ETA: 0s - loss: 0.1822 - accuracy: 0.9404WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.1841 - accuracy: 0.9390 - val_loss: 0.5428 - val_accuracy: 0.7175\n","Epoch 6/100\n","53/63 [========================>.....] - ETA: 0s - loss: 0.1632 - accuracy: 0.9399WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.3072 - val_accuracy: 0.8675\n","Epoch 7/100\n","53/63 [========================>.....] - ETA: 0s - loss: 0.1440 - accuracy: 0.9469WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9470 - val_loss: 0.5077 - val_accuracy: 0.7500\n","Epoch 8/100\n","54/63 [========================>.....] - ETA: 0s - loss: 0.1287 - accuracy: 0.9491WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 0s 6ms/step - loss: 0.1282 - accuracy: 0.9490 - val_loss: 0.3888 - val_accuracy: 0.8125\n","Epoch 9/100\n","34/63 [===============>..............] - ETA: 0s - loss: 0.1165 - accuracy: 0.9513"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a4c08db4994b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcnn_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdense_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"i3wqKrSyVBqr"},"source":["## Instructor-Led Discussion: Overfitting\n","\n","**Questions:**\n","Was the best epoch necessarily the last epoch? \n","\n","You should check what the best epoch was at every step of the way!\n","\n","**When does your model overfit?**"]},{"cell_type":"markdown","metadata":{"id":"G5scKiYAYE8g"},"source":["\n","# Milestone 4. Expert models: Transfer learning"]},{"cell_type":"markdown","metadata":{"id":"FybhlxdVYFbv"},"source":["\n","## Instructor-Led Discussion: Transfer Learning\n"]},{"cell_type":"markdown","metadata":{"id":"laXN17IK23GY"},"source":["For all of the machine leanring we've done thus far, we've used models that were built from 'scratch'. All of these models are like newborn babies that have neither seen nor explored the world. \n","\n","And, despite their cuteness, these babies require **a lot of education** to do much anything useful. "]},{"cell_type":"markdown","metadata":{"id":"3Bx5nyzE36EQ"},"source":["Unfortunately, our training manual is pretty small to all the things in the big wide world. So, just training on our manual is going to be inherently limited. \n","\n","\n","Luckily, there are **non-babies** (who we will refer to as experts) who have been out in the world for a long time! While these non-babies haven't seen our task, they have experience with a lot of other things. We can hand them our training manual and reasonably expect that they will pick up our task fairly quickly. \n","\n","In deep learning, the idea of using a model trained on another task as a starting point for your model is known as **transfer learning**. "]},{"cell_type":"markdown","metadata":{"id":"DChmzlt3ARPy"},"source":["### VGG 16"]},{"cell_type":"markdown","metadata":{"id":"lFtHOYI2AdSs"},"source":["For our transfer learning, we're going to use 'experts' built upon the famous 'ImageNet' classification problem. \n","\n","In ImageNet, participants were challenged to build machine learning models that could distinguish 14 million images' categories, where there were > 20,000 categories available. \n","\n","Below, we see examples of 4 different categories. \n","\n","![](http://cs231n.github.io/assets/trainset.jpg)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J-E_AiG-CFj0"},"source":["One of the experts we can use is VGG 16. VGG 16 wasÂ a network that was allowed to study the 14 million images 74 times. \n","\n","After its studying, VGG 16 was able to guess something close to the real label (top-5 accuracy) better than a human can."]},{"cell_type":"markdown","metadata":{"id":"IvkajtdHAbzL"},"source":["![](https://cdn-images-1.medium.com/max/1600/0*V1muWIDnPVwZUuEv.png)"]},{"cell_type":"markdown","metadata":{"id":"Vwj8o5X3D325"},"source":["We're going to take an expert model like VGG16 and let it train on OUR x-rays. Hopefully, their experience with those 14 million images will help it understand pneumonia from our x-rays. "]},{"cell_type":"markdown","metadata":{"id":"g-357WWC7qJJ"},"source":["### Exercise (Coding) | Within a student group"]},{"cell_type":"markdown","metadata":{"id":"uz_mVsECHvro"},"source":["Let's tap an expert model to help us out with our pneumonia prediction!\n","\n","We provide a wrapper that lets you 'call' up and employ expert models. You can call it like...\n","\n","```\n","transfer = TransferClassifier(name = 'VGG16')\n","```\n","\n","The experts we have on hand are:\n","* `VGG16`\n","* `VGG19`\n","* `ResNet50`\n","* `DenseNet121`\n","\n"]},{"cell_type":"code","metadata":{"id":"0VB79BCx7tvg","executionInfo":{"status":"ok","timestamp":1605382683877,"user_tz":480,"elapsed":169301,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"675d25e5-c5f1-4bd1-9398-25099fdfe4a9","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["### YOUR CODE HERE\n","\n","transfer = TransferClassifier(name = 'VGG16')\n","transfer_history = transfer.fit(train_data, train_labels, epochs=50, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","transfer_score = transfer.evaluate(train_data, train_labels, verbose = 0)\n","plot_acc(transfer_history)\n","\n","### END CODE"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"," 1/63 [..............................] - ETA: 0s - loss: 0.6457 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0162s vs `on_train_batch_end` time: 0.0286s). Check your callbacks.\n","63/63 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 4s 60ms/step - loss: 0.6136 - accuracy: 0.6775 - val_loss: 0.4855 - val_accuracy: 0.8375\n","Epoch 2/50\n","63/63 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9155WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 51ms/step - loss: 0.2687 - accuracy: 0.9155 - val_loss: 0.2875 - val_accuracy: 0.8850\n","Epoch 3/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9370WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1799 - accuracy: 0.9370 - val_loss: 0.6175 - val_accuracy: 0.7575\n","Epoch 4/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9531WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1371 - accuracy: 0.9525 - val_loss: 0.2920 - val_accuracy: 0.8900\n","Epoch 5/50\n","63/63 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9680WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1011 - accuracy: 0.9680 - val_loss: 0.3548 - val_accuracy: 0.8825\n","Epoch 6/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.9662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1018 - accuracy: 0.9660 - val_loss: 0.9175 - val_accuracy: 0.7300\n","Epoch 7/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9675WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0862 - accuracy: 0.9675 - val_loss: 0.6115 - val_accuracy: 0.8100\n","Epoch 8/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.9125 - val_accuracy: 0.7575\n","Epoch 9/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0672 - accuracy: 0.9775 - val_loss: 0.5946 - val_accuracy: 0.8400\n","Epoch 10/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0578 - accuracy: 0.9805 - val_loss: 1.1852 - val_accuracy: 0.6825\n","Epoch 11/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0466 - accuracy: 0.9845 - val_loss: 0.8825 - val_accuracy: 0.7825\n","Epoch 12/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9793WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0588 - accuracy: 0.9795 - val_loss: 1.4659 - val_accuracy: 0.6400\n","Epoch 13/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 54ms/step - loss: 0.0419 - accuracy: 0.9855 - val_loss: 1.5301 - val_accuracy: 0.6500\n","Epoch 14/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9840WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0426 - accuracy: 0.9840 - val_loss: 1.3379 - val_accuracy: 0.6675\n","Epoch 15/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9819WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0492 - accuracy: 0.9820 - val_loss: 1.2666 - val_accuracy: 0.6975\n","Epoch 16/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9889WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.7748 - val_accuracy: 0.8125\n","Epoch 17/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9909WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0319 - accuracy: 0.9905 - val_loss: 0.7594 - val_accuracy: 0.8200\n","Epoch 18/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9919WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.8577 - val_accuracy: 0.8100\n","Epoch 19/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9919WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.9011 - val_accuracy: 0.8025\n","Epoch 20/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 1.5785 - val_accuracy: 0.6400\n","Epoch 21/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9919WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 1.2965 - val_accuracy: 0.7275\n","Epoch 22/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9970WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0159 - accuracy: 0.9970 - val_loss: 1.4313 - val_accuracy: 0.7200\n","Epoch 23/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9960WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 1.6477 - val_accuracy: 0.6725\n","Epoch 24/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9884WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.5988 - val_accuracy: 0.8375\n","Epoch 25/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9929WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 1.1224 - val_accuracy: 0.7625\n","Epoch 26/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9975WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 2.0606 - val_accuracy: 0.6375\n","Epoch 27/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9965WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 1.5284 - val_accuracy: 0.7000\n","Epoch 28/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6230 - val_accuracy: 0.7375\n","Epoch 29/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.8454 - val_accuracy: 0.7175\n","Epoch 30/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9950WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0103 - accuracy: 0.9950 - val_loss: 2.4632 - val_accuracy: 0.6125\n","Epoch 31/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 2.4300 - val_accuracy: 0.6175\n","Epoch 32/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9793WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0615 - accuracy: 0.9795 - val_loss: 1.2707 - val_accuracy: 0.6775\n","Epoch 33/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9955WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 1.1300 - val_accuracy: 0.7700\n","Epoch 34/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9980WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 1.5453 - val_accuracy: 0.7450\n","Epoch 35/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9985WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 1.4485 - val_accuracy: 0.7425\n","Epoch 36/50\n","63/63 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8487 - val_accuracy: 0.7050\n","Epoch 37/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6952 - val_accuracy: 0.7375\n","Epoch 38/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8214 - val_accuracy: 0.7500\n","Epoch 39/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8933 - val_accuracy: 0.7400\n","Epoch 40/50\n","62/63 [============================>.] - ETA: 0s - loss: 8.5575e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 8.4893e-04 - accuracy: 1.0000 - val_loss: 2.1170 - val_accuracy: 0.7075\n","Epoch 41/50\n","62/63 [============================>.] - ETA: 0s - loss: 6.3448e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 53ms/step - loss: 6.3048e-04 - accuracy: 1.0000 - val_loss: 2.0495 - val_accuracy: 0.7275\n","Epoch 42/50\n","63/63 [==============================] - ETA: 0s - loss: 7.4640e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 7.4640e-04 - accuracy: 1.0000 - val_loss: 1.7969 - val_accuracy: 0.7575\n","Epoch 43/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7123 - val_accuracy: 0.7725\n","Epoch 44/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9985WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 1.3272 - val_accuracy: 0.7975\n","Epoch 45/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9965WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 2.1400 - val_accuracy: 0.6725\n","Epoch 46/50\n","62/63 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 1.8437 - val_accuracy: 0.7550\n","Epoch 47/50\n","63/63 [==============================] - ETA: 0s - loss: 7.9813e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 7.9813e-04 - accuracy: 1.0000 - val_loss: 2.1580 - val_accuracy: 0.7025\n","Epoch 48/50\n","62/63 [============================>.] - ETA: 0s - loss: 5.1957e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 5.2086e-04 - accuracy: 1.0000 - val_loss: 2.0955 - val_accuracy: 0.7125\n","Epoch 49/50\n","62/63 [============================>.] - ETA: 0s - loss: 9.9728e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 9.9318e-04 - accuracy: 1.0000 - val_loss: 2.2577 - val_accuracy: 0.6950\n","Epoch 50/50\n","62/63 [============================>.] - ETA: 0s - loss: 4.3940e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","63/63 [==============================] - 3s 52ms/step - loss: 4.6796e-04 - accuracy: 1.0000 - val_loss: 2.1653 - val_accuracy: 0.7200\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVd6A3zOZJJPeSSUhYAg9CVVQBFRELLgqq7IW0BXbWtZdy+qqa9uq67ruqmtnP0URUVkLWFCagiIl9BAgBNJJn7RJmTnfH3dm0qYlmUm97/PcJ5N7z733zCRzf+fXhZQSFRUVFZWhi6avJ6CioqKi0reogkBFRUVliKMKAhUVFZUhjioIVFRUVIY4qiBQUVFRGeKogkBFRUVliOMxQSCEeFMIcVoIccDOcSGEeEEIcUwIsU8IMdlTc1FRUVFRsY8nNYIVwIUOji8EUszbLcDLHpyLioqKioodPCYIpJRbgAoHQy4D/k8q/ACECiFiPTUfFRUVFRXbaPvw3vFAXpvf8837ijoOFELcgqI1EBAQMGXMmDG9MkF7HCk/AkBqRGqfzkOlG0gJzXXKT40XCK/Wn0K44wbQVA9Ndcr1hBdoNO3vY2xUxjSbN2Oz40sKDXj7g28g+AQom/Byw1xtYGyClsbWzdSkfFbS1PoT809TC5iMnplHX6LRKpuXN3j5tNm8lc3YrHw2xjafk7FR+Xw8TchwCIjs1qm7du0qk1JG2TrWl4LAZaSUrwKvAkydOlXu3LmzT+czd8VcADYt29Sn81BxEX0hHP0Ksr+CnE2KILCFly/EZcCZt8GYS8HLha+HyQSnD8GJzZCzGU5+D021LkxKQGQKxE1W7hmXoXzBG/Vg0Lf/WXkS8n6Aon0ga5Vzo8dD/GTwDQatL2h1ysNKq1MExbhFoAtxPg0p4bt/wL73oSJHEQQWvAMgZBR4+5nv4at8Rpb7BUSat2EQEAWBw8A/QpnHQKHFAHVlUFcKdaeV17WnobYE9AVQna+8toXWDyLGQvhIiBgFgdHK30MX3P6nVue++epClAVBNxBCnLR3rC8FQQEwvM3vCeZ9KkOFlkbzF7AUaktbX7c02h4fEg9jFylfMGeUHoF9qyH7SyjZr+wLToC0q+GM+coXqt1DtxoaKiHrM/hgmTJ2xi0w+QbwC2t/7cpc5aF/YjOc2KLMGSB8FEy6GkbOgaSzlJW8oRoaa9rcq0Z5HzGTXHsfbWmshYJdcOoHOLUdstZBc4OyGjW1tB+7/UW49gMIHW77WqAIsfX3w0+vw4jZkHIBRJyhPNTCR0FQjJu0pH5OxCjHx1saW4VCTQkERZs/n1hF2xsECE8WnRNCjAA+k1JOsHHsYuBO4CJgBvCClHK6s2v2B41gQ84GAM4feX6fzqPfU1MCR9ZBTbF5tVXauuKqK4PG6q5fU+unrHbTr1UeXm2/iIZqOPAh7FkJBTsV88nwGTD6AkhZAMPGOn+wmYyQ/QX88DLkblVMMum/gITpcPI7RQBUmRdWgTHKQz95jvIzJKHr78ddmIxmM4UBCnbDmpuUlfy1qyE2rfN4YzOsvQP2r4ZZd8P8J4fGQ38II4TYJaWcavOYpwSBEOI9YC4QCZQAfwC8AaSU/xFCCODfKJFF9cCNUkqnT/j+IAgGPQ1VygrTL0yxa3cFKZUH6E9vKKtrUwsgwD9cMR9YN7NJIdDy+zDzvijl4dv5wlCYCZnvwP4PFSESmghpv1DMKgc+hMOfKA/CqLGQca2yOg8c1v3PoWgf/Pgf2P+BYjLxDYERZysP/ZFzIXJ0/314nj4M7ywGQxX8fAWkzG891tygaD3ZX8B5j8HZv+m/70PFbfSJIPAU/UEQZBZnApAek96n83BIVV6rCaHyBCTOVFT/mEm21VmDHrI+Vx56OZtAGhXThr/54Wx5YAfFKA6rkAQIjlde+4crD5zM92Dnm1B+FHShkHEdZFyvmBtcsbe7SnMDHP5MEQo5mwGpmHomLFYEQNxk9z7YaksV00D0BPe+D0+jL4J3fw4lh+CSf8CUpcrf+b0lii/j4mdh2s29MpXm5mby8/MxGAy9cr+hjE6nIyEhAW9v73b7VUHgZvqds7ixFkqzoHCP+eH/A+jzlWM+gcrDujQLkIpDK2W+IhSSzoKT2+DAGsWW3mJQVtkTFisP/LrSVjNO3WnldU2xYpNui9ZPiSIxNkLCNJj6Sxj/M8U04Wmq8pT3NmI2eLvRKTdYaKyB1Uvh+DeKCejEFig5AJe/AhMX99o0Tpw4QVBQEBEREQhV+/AYUkrKy8upqakhOTm53TFHgmAALW+GGOXHlQdvJyTUFCmrvNOHoORgq80aFAdW4kxIvBsSz4Rh45VVbG0pHNsAR7+EQ5/CnndazwmIgslLlQdDwjTHq2kpob4cqvMU55llA8UUEzvJLW/fZUKHO3aIDnV8g+AX78Pnv4FtLygRLNe8C6MX9Oo0DAYDI0aMUIWAhxFCEBERQWlpaZfOUwVBf6P2NGx4QjF7OEJ4KSaX+MmK+SV6HMRMVFb/tr5sgVGQvkTZjM2Qt0MxG8VlKM5OV00eQrSGDcZldP39qfQ+Xt5w6QvKAiEyFRKm9Mk0VCHQO3Tnc1YFQX+hpQl2vAKb/6bYwGfdBaPOsz3WPwKiUpV47u7g5Q0jzlI2laGBEEr0k4qKDQZHEOxA5+gGeHkWfPWIYs654we44GkYNc/2Fjup+0JARWUIMm/ePL788st2+55//nluv/12m+Pnzp2LxRd50UUXUVVV1WnM448/zrPPPuvwvmvXruXQoUPW3x977DE2bNjQ1el7HFUj6AZ/Ou9PnXdKCT+8pCT5BMcpUTUhCa0RNv7hUF/RPnuxrhSKMuH4t0qCyi9W97rtVkVlKLBkyRJWrVrFggWt369Vq1bxt7/9zem569at6/Z9165dyyWXXMK4ceMAePLJJ7t9LU+iCoJuMGv4rPY7TEb44new41Ulhr36FBws7Jzt2RGNVklKmv8kzLgdtAMoNV9FZQCxePFiHnnkEZqamvDx8SE3N5fCwkLee+89fvOb39DQ0MDixYt54oknOp07YsQIdu7cSWRkJH/84x/573//y7Bhwxg+fDhTpij+ltdee41XX32VpqYmzjjjDN5++20yMzP55JNP2Lx5M08//TQffvghTz31FJdccgmLFy/mm2++4b777qOlpYVp06bx8ssv4+vry4gRI1i6dCmffvopzc3NfPDBB3i6vpoqCLrBtrxtgFkgtDTCR7fAobWKXf/8J5U4fZNRWfVX5ysRNg0Vim2/bVKVLnTQpKirqLjKE58e5FCh3q3XHBcXzB8uHW/3eHh4ONOnT2f9+vVcdtllrFq1iquuuoqHH36Y8PBwjEYj5513Hvv27WPSJNuRb7t27WLVqlVkZmbS0tLC5MmTrYLgiiuuYPny5QA88sgjvPHGG9x1110sWrTI+uBvi8FgYNmyZXzzzTeMHj2aG264gZdffplf//rXAERGRrJ7925eeuklnn32WV5//XV3fEx2UZ9C3eDhbx7m4W8eVpJzVi5WhMAFTyub5cGu8YLgWBg+DSZcoSTujL9cyUyNSlVMRaoQUFHpNSzmIVDMQkuWLGH16tVMnjyZjIwMDh482M6e35GtW7dy+eWX4+/vT3BwMIsWLbIeO3DgALNnz2bixImsXLmSgwcPOpzLkSNHSE5OZvTo0QAsXbqULVu2WI9fccUVAEyZMoXc3NzuvmWXUTWC7mJsghUXKan8l7+qFDNTUVFxiqOVuye57LLLuPfee9m9ezf19fWEh4fz7LPP8tNPPxEWFsayZcu6nfm8bNky1q5dS1paGitWrGDTpk09mquvrxIM4uXlRUuLExOzG1CXpN2huUGpQ1OeA0veV4WAisoAIDAwkHnz5nHTTTexZMkS9Ho9AQEBhISEUFJSwvr16x2ef84557B27VoaGhqoqanh008/tR6rqakhNjaW5uZmVq5cad0fFBRETU1Np2ulpqaSm5vLsWPHAHj77beZM2eOm95p11E1gq5SuAeK9ymvb/wU4vsmOUdFRaXrLFmyhMsvv5xVq1YxZswYMjIyGDNmDMOHD+essxzn1UyePJmrr76atLQ0hg0bxrRp06zHnnrqKWbMmEFUVBQzZsywPvyvueYali9fzgsvvMCaNWus43U6HW+99RY///nPrc7i2267zTNv2gXUWkNd4fi38P71zDVVQfQENi3/sW/moaIywDh8+DBjx47t62kMGWx93mqtIXewfw18fBtEpfL8BU90u12cioqKSn9DFQSu8MPLSp5A0tmw5F3SXWkBqKKiojJAUAWBI6SEb55QerqOXQRXvAbeOrVDmYqKyqBCFQT2MJngk7uUKqBTb4KLnrV263p6y9OAKghUVFQGB6ogsMeWZxQhcM4DMO9htZWfiorKoEXNI7DFkS9g059g0jWqEFBRURn0qIKgI2XH4KPlEJsGlz6vCgEVlUFAeXk56enppKenExMTQ3x8vPX3pqYmh+fu3LmTu+++2+k9Zs2a5XRMf0U1DbWlsQZW/UJp3HL1O73Tc1dFRcXjREREkJmZCSh9BAIDA7nvvvusx1taWtBqbT8Op06dytSpNsPv27Ft2zb3TLYPUDUCCyaTkidQfgx+vkJp4m6HVy55hVcueaX35qaiouJ2li1bxm233caMGTN44IEH2LFjBzNnziQjI4NZs2Zx5MgRADZt2sQll1wCKELkpptuYu7cuYwcOZIXXnjBer3AwEDr+Llz57J48WLGjBnDtddeiyVxd926dYwZM4YpU6Zw9913W6/b16gagYXvnoOsz2DBnyD5HIdDUyNTe2lSKiqDkPW/g+L97r1mzERY+Jcun5afn8+2bdvw8vJCr9ezdetWtFotGzZs4OGHH+bDDz/sdE5WVhYbN26kpqaG1NRUbr/9dry9vduN2bNnDwcPHiQuLo6zzjqL77//nqlTp3LrrbeyZcsWkpOTWbJkSbffrrtRBQHA0a/h26dh4s/hzDucDv/0iFJs6tLUSz09MxUVFQ/y85//HC8vJSy8urqapUuXcvToUYQQNDc32zzn4osvxtfXF19fX4YNG0ZJSQkJCQntxkyfPt26Lz09ndzcXAIDAxk5ciTJycmAUvfo1Vdf9eC7cx1VENSehg9/CdET4NIXXHIO/3373wFVEKiodIturNw9RUBAgPX1o48+yrx58/j444/Jzc1l7ty5Ns+xlIgG+2WiXRnTn1B9BEV7wVCt/HP6+Pf1bFRUVPqI6upq4uPjAVixYoXbr5+amkpOTo610cz777/v9nt0F1UQ1FcoP4Ni+3YeKioqfcoDDzzAQw89REZGhkdW8H5+frz00ktceOGFTJkyhaCgIEJC+kfdMo+WoRZCXAj8E/ACXpdS/qXD8STgTSAKqACuk1LmO7qm28tQ//Af+OJBeOCE0j7SBeaumAvApmWb3DcPFZVBjFqGWqG2tpbAwECklPzqV78iJSWFe++91+336WoZao9pBEIIL+BFYCEwDlgihBjXYdizwP9JKScBTwJ/9tR87NJQAQhQK4qqqKh4mNdee4309HTGjx9PdXU1t956a19PCfCss3g6cExKmQMghFgFXAa07Q49DviN+fVGYK0H52ObhkpFCJgLyrnC25e/7cEJqaioDFbuvfdej2gAPcWTPoJ4IK/N7/nmfW3ZC1xhfn05ECSEiPDgnDrTUOmyScjC8JDhDA8Z7qEJqaioqPQufe0svg+YI4TYA8wBCgBjx0FCiFuEEDuFEDtLS0vdO4P6CvAL69Ip7x94n/cP9B+Pv4qKikpP8KRpqABou2xOMO+zIqUsxKwRCCECgSullFUdLySlfBV4FRRnsVtn2VAJ/l1TQl7e+TIAV0+42q1TUVFRUekLPKkR/ASkCCGShRA+wDXAJ20HCCEihRCWOTyEEkHUuzR0XSPQNzRTXtdEs9HkoUmpqKio9B4eEwRSyhbgTuBL4DCwWkp5UAjxpBBikXnYXOCIECIbiAb+6Kn52KWhssuCIKesjqMlNcz+60Ze3HiMyjrHZWxVVFT6B8XFxVxzzTWMGjWKKVOmcNFFF/Hqq6/2m+JvfYVHS0xIKdcB6zrse6zN6zXAGk/OwSHGFjBUs+FkM9Pqmwnx93Z6SovRRGOLiTB/H86IDOSZL4/wr2+PcnlGAjedNYKU6KBemLiKikpXkVJy+eWXs3TpUlatWgXA3r17+eSTT5ycOfjpa2dx32KoBmBrvpHtOWUunVJUbUBKSViAD+/cPIMvf30OP0uP58Pd+cz/xxYe/+SgJ2esoqLSTTZu3Ii3tze33XabdV9aWhqzZ8+mtrbWZtnoJ598kmnTpjFhwgRuueUW6/65c+fy4IMPMn36dEaPHs3WrVsBMBqN3HfffUyYMIFJkybxr3/9C4Bdu3YxZ84cpkyZwoIFCygqKurld++YIV10TjZUIIBKGcjJ8nqXzsmrqCeq6SGemTcFgNSYIP5y5STuX5DK/Wv2sXpnHn+4dBxC7WymomIfWwXdrroK7rgD6uvhoos6H1+2TNnKymDx4vbHNm1yessDBw4wZcoUm8dslY0+++yzufPOO3nsMcWIcf311/PZZ59x6aVKscmWlhZ27NjBunXreOKJJ9iwYQOvvvoqubm5ZGZmotVqqaiooLm5mbvuuov//e9/REVF8f777/P73/+eN9/sfZeoPYa0RpCbp1SzqCaQUxUuCoLKerwIYVJc+zyCiEBfZo2KoL7JiL6hf1caVFFRaY+lbLRGo7GWjQZFi5gxYwYTJ07k22+/5eDBVo3/iiuUFKgpU6ZYx2/YsIFbb73V2u0sPDycI0eOcODAAebPn096ejpPP/00+fkOK+n0OkNaI9hx+DjJgC440nVBUNFAvXYDX+WW8Mvwm9odiw1RWlsWVje45G9QURmyOFrB+/s7Ph4Z6ZIG0JHx48ezZo1tl6StstEGg4E77riDnTt3Mnz4cB5//HEMBkOnc5yVmZZSMn78eLZv397lOfcWQ1YjMJokh4/nAhAbE9sljaDRZyNv7/u/TsdiQ3UAFFU3uG2eKioq7uHcc8+lsbGxXTOYffv2We37HbE89CMjI6mtrbUrRNoyf/58XnnlFatgqKioIDU1ldLSUqsgaG5ubqdZ9AeGrCDYfrwcjUHJXQuLjKagsoEWF/IC8irq8fW2/bHFhlgEgcHmcRUVlb5DCMHHH3/Mhg0bGDVqFOPHj+ehhx4iJibG5vjQ0FCWL1/OhAkTWLBgAdOmTXN6j5tvvpnExEQmTZpEWloa7777Lj4+PqxZs4YHH3yQtLQ00tPT+12je4+WofYE7ipD/ZvVmaQe+ie3iLWsXriHBz86yNYH5jE83HFzmml/3ECJz+8YGRXYqQy10SQZ/ch6bp8zivsWqH2NVVQsqGWoe5d+U4a6P1Pf1MKXB4qZFC4RulCGRwQCODUPGZqNlNY04qu1XanUSyOIDvKlUDUNqaioDCCGpCD4+lAJdU1GUoKbwT+cpAilb6mzENL8SuW4PdMQQGyoH0VVqmlIRUVl4DAko4Y+3lNAfKgfEZo68AsjJliHt5dwqhHkVSgr/VcWfkBGou3S1bEhOg4UVLt9zioqKiqeYshpBKU1jWw9WsZl6XGIhkrwC8dLI0gI8yfPiSCwCIqUqEj8vW37EmJDdNbsYxUVFZWBwJATBJ/uLcRoklyeEd+u8mhiuD8nK+ocnptXUY+vVsMHWW/w0k8v2RwTG+JHY4uJyvpmt89dRUVFxRMMOUGwNrOACfHBSnG4hqp2guCUEx9BXmU9w8P9+eDQB6w+uNrmmDhzLkFhleowVlFRGRgMKUFw7HQt+/Kr+Vl6PBiboVFvbVOZFOGP3tBCVb39ktJ5FQ0MD/NzeA9LdrGaS6Ci0r/w8vIiPT2dtLQ0Jk+e3O1Y/ueff576etuLxrlz55Kamkp6ejrp6eks7lgTqYeMGDGCsjLXCmR2hSHlLF67pwCNgEVpcYo2AFaNwJI/cKqinlB/H5vn51XWM3VEGCcq7d/DklRWrIaQqqj0K/z8/MjMzATgyy+/5KGHHmLz5s1dvs7zzz/Pddddh7+/bT/hypUrmTrVZrh+v2XIaAQmk2RtZgFnp0QxLFin+AfAKgiSIpQ/qr0Q0ur6ZmoMLQwPc5xwFhnoi7eXoNBDGsGx07XklNZ65NoqKkMFvV5PWFhrQ6pnnnmGadOmMWnSJP7whz8AUFdXx8UXX0xaWhoTJkzg/fff54UXXqCwsJB58+Yxb948l++3bNkybrvtNqZOncro0aP57LPPAKWMxY033sjEiRPJyMhg48aNgP1y1gD/+te/mDx5MhMnTiQrK8sdH8fQ0Qh2nqwkv7KB314wWtnRYF7WWzSCsFaNwBZ55hyC4eF+kGP/PhqNIDpYR5GHfAT3rNpDiJ837y4/0yPXV+nMibI6TlXUM2d0VF9PZdAwd8XcTvuuGn8Vd0y7g/rmei5a2bkM9bL0ZSxLX0ZZfRmLV7c3uXTM8rdFQ0MD6enpGAwGioqK+PbbbwH46quvOHr0KDt27EBKyaJFi9iyZQulpaXExcXx+eefA1BdXU1ISAjPPfccGzduJDIy0uZ9rr32Wvz8FBPx/PnzeeaZZwDIzc1lx44dHD9+nHnz5nHs2DFefPFFhBDs37+frKwsLrjgArKzs3nrrbc6lbO2EBkZye7du3nppZd49tlnef31152+d2cMGUGw+1QlAT5eLBhvritiEQRmH0GAr5bIQB+7IaSW/Qlh/k7/6eJC/DyiEdQ3tZBVXEN8qGM/hYp7eXHjMT7dW8j+xxfgox0ySvSgo61paPv27dxwww0cOHCAr776iq+++oqMjAwAamtrOXr0KLNnz+a3v/0tDz74IJdccgmzZ8926T72TENXXXUVGo2GlJQURo4cSVZWFt999x133XUXAGPGjCEpKYns7Gw2bNjAbbfd1q6ctYW25a8/+uij7n8gbRgyguC2OaO4Ztpw/H3Mb7m+vWkIzCGkdkxDrRqBY9MQKFVId59y4EjoJgcL9RhNkmJznoLa/KZ3KK420Nhi4mBhNRmJXetvrWIbR4spf2/Hi61I/0iXNABHzJw5k7KyMkpLS5FS8tBDD3Hrrbd2Grd7927WrVvHI488wnnnnWdtUtMdOn5fu/v9dbX8dVcYUsubdk7gDqYhMIeQ2tUIGgjWaQnx8+bZbc/y7LZn7d4nJkRHSXUjJpN7k8r25ikO7iajiYo6+9FNKu6lWK9od7tOul+4q/QNWVlZGI1GIiIiWLBgAW+++Sa1tYrvraCggNOnT1NYWIi/vz/XXXcd999/P7t37wYgKCiImpqaLt/zgw8+wGQycfz4cXJyckhNTWX27NmsXLkSgOzsbE6dOkVqaqrNctaeZMhoBJ1oqADhBb7B1l2JEQF8sreQphZTJxPAqYp6Es0O5c+yFUfPfbPus3npuBA/mowmyuuaiArytTmmO+zLby1dUVRtICLQfddWsU9JG0Fws2vWAZV+iMVHAEqzmP/+9794eXlxwQUXcPjwYWbOnAlAYGAg77zzDseOHeP+++9Ho9Hg7e3Nyy+/DMAtt9zChRdeSFxcnNW525a2PoLIyEg2bNgAQGJiItOnT0ev1/Of//wHnU7HHXfcwe23387EiRPRarWsWLECX19fbr75ZrKzs5k0aRLe3t4sX76cO++802OfjUNBIITQAZcAs4E4oAE4AHwupexfnRW6SkOlog20Uc8Sw/0xSSioaiA5MqDd8LzKelKjg1y6dGtfggY3C4IqawmL4moDE+JD3HZtFdvUN7VQY1BWZTtPVqomuQGM0Wi0e+yee+7hnnvuabdv1KhRLFiwoNPYu+66y2rX78gmB53Tzj//fP7zn/+026fT6Xjrrbc6jdVqtTz33HM899xz7fZbWmICTJ061eH9uoJd05AQ4gnge2Am8CPwCrAaaAH+IoT4WggxyS2z6AvqK6yOYguJ4ZYQ0valJkwmSX5lg0v+AYA4szO30I1VSKvrm8ktr+eCcdFAq7lioKI3NLvddOYJSvSNAGQkhlJa00h+pZofojL4cKQR7JBS/sHOseeEEMOARA/MqXewaARtsOQSdIwcKq1tpKnF5DSr2EJMiPtbVu4rUPwD546N5p0fT1E8ADOXpZRsOVrGm9+dYHN2KWkJIfxh0Xgm92MHrOVzvnhiLHtOVbHrZKXLCwIVFQsrVqzo6yk4xK5GIKX83NGJUsrTUsqetwrrKxoqwK+9RhAV6IuvVtMpcsgaOmp+APh5++HnbV8oRAT44KPVuPVhbXEUpw8PJTrId0CVsGhoMrLyx5PM/8cWlr65g0NFem48awRF1QaueGkbv1mdyel+quFY/AOzU6II9NWy86RnnXaDGbUib+/Qnc/ZqbNYCDEauB9IajteSnlul+/Wn2ioguiJ7XZpNMJm5JA1dNScdLb+2vUOLy2EIDZE59Zcgr351YyMDCDEz5uYEB3F+v5vojCaJP/4Opu3fzhJdUMz4+OCee6qNC6eFIuv1ovfXpDKixuP8cbWE3x5oJg7z03hprNH2O0A1xdYBEFcqI6MxFB2nazq4xkNTHQ6HeXl5URERKg+Fg8ipaS8vBydTtel81yJGvoA+A/wGmDf2zLQsGEaAtshpJaGNAkumobA3JfASXax0SR554eTLJ6SQICv4z/FvvwqZo6MABTTU1Zx18PXepsNh0v498ZjnD92GLecM4ppI8LaPQQCfbU8eOEYrp46nKc/P8xfv8ji/Z9O8dsLUlk4IQatV99HNxfrDfj7eBHoq2VyYhj/+vYoNYZmgnTefT21AUVCQgL5+fmUlpb29VQGPTqdjoSEhC6d44ogaJFSvty9KfVTWpqgqRb8bQiCCH+255S3iw7Jq6hnWJAvOm9lpfrU5qcAeHTOo3ZvERfix48nHJsRth0v4w+fHKTZaOLm2SPtjivRGyjRNzIpIRSAmGA/Nh0p7fcRLMdOK3HZ/7wmw6GgGxEZwOtLp7I5u5SnPjvEXe/tIS5Exw2zRnDNtOF2iwD2Bqf1jcQE6xBCMHVEGCYJmXlVzE5Ry010BW9vb5KTk/t6Gip2cGXJ9akQ4g4hRKwQItyyuXJxIcSFQogjQns/DwgAACAASURBVIhjQojf2TieKITYKITYI4TYJ4ToXGDEE9hIJrOQGO5PfZOR8jYJW5Y+BBa+OfEN35z4xuEtYkJ0lOgNGB1ExmSeUswMXxwodngti38gbbgSLhoboqO+yYje4J6sQk9xoqyO6GBfp9qOhTmjo/jq1+fw+g1TGREZwF/WZzHzz9/yyNr9VqHS2xTrDUQHK2p2+vBQNAJ25qqJZSqDC1cEwVIUH8E2YJd5c+okFkJ4AS8CC4FxwBIhxLgOwx4BVkspM4BrANttv9yNtfJoZ3nWGkLaah7Kq2iw7neV2FA/WkySstpGu2MyzQ/4nScrHTqW9+ZX4aURjItVBIElKqmknzpYLeSU1nbKx3CGRiM4f1w07y4/k/X3zObStFhW78zn/Oc286d1hz00U/sUVxuIDlZyQYJ03qTGBHukfIiKSl/iVBBIKZNtbPbtGK1MB45JKXOklE3AKuCyjpcHLKm9IUBhVybfbRxoBB1DSJuNJoqqnTek6UhciONOZVJKMvOqSB+umHu+PGhfK9iXX01qdBB+PoppqjVhrX8LghNldSRHBnb7/LGxwfxtcRrbfncuZ58RyYe78t04O+dIKTldYyA6pNXxNiUplD2nqhxqeioqAw2ngkAI4S2EuFsIsca83SmEcMVTFg/ktfk937yvLY8D1wkh8oF1gM10PSHELUKInUKInW5xNlkKzvl31ggSwtprBIVVDZhka+ioqzjrVJZf2UB5XRNXTkkgZVgg6w8U2RwnpWRffrXVLAStGkF/bn5TWddEZX0zI7uoEdgiMtCXqSPCKK9rorGl9+IVKuqaaDZKooPaCoIwahtbODIAnPUq3eOzfYWc+advHHYrHGy4Yhp6GZiCYrZ5yfzaXc7jJcAKKWUCcBHwthCi05yklK9KKadKKadGRbnBSedAI9B5exETrLNGDlkihto2pInwjyDCP8LhLWKdaAQWs1DG8FAWToxlx4kKSms6m5FOltdT3dBsdRQDDAvSIUT/1ghOmLOzR0b1XBBA6+d5Wm/f1OZuLFnFMW00gqlJyuJhl5pPMCgpqm7goY/2U6w3DIjIPHfhiiCYJqVcKqX81rzdCExz4bwCYHib3xPM+9ryS5SyFUgptwM6wHa3B3fiQBCA4iewmIbaNaQx8+FVH/LhVR86vEWovzc6b/tJZZl5VfhqNaTGBLFwQgwmCV8d6mwe2puvCIxJCa0agY9WQ0SAb7/OLj5RqgiCrvoI7GFx2PamX8RyL8u9QQkhjgryVSuRDkKklDywZh8NTYrWecpOSfrBiCuCwCiEGGX5RQgxEtfyCX4CUoQQyUIIHxRn8CcdxpwCzjNfdyyKIPB8oHFDBWi8wce2/Toxwp+TFcqDLK+iHq1GWE09riKEIC7Ez+6qPTOvionxIXh7aRgTE0RyZIDN6KF9+dX4ajWM7lDwzlJ8rr9yoqwOL41wWzkGqzmsTwRBa+FAIQRTk8LYqQqCQcc7P5xk69EyHr1kHFqNsD4DhgKuCIL7gY1CiE1CiM3At8BvnZ0kpWwB7gS+BA6jRAcdFEI8KYRYZB72W2C5EGIv8B6wTPZGHrqNyqNtSQz3p0TfiKHZSF5lA3GhfnhpWsc+tOEhHtrwkNPbxIbqKLRhx282mjhQUE2a2VEshODCCTFsO15OZYc+A3vzqphgFhhtiQnR9WuNIKeslsRw/07z7i4xwRa/SO+9Z4vQGRbUPktzSlIY+ZUN/T5qS8V1TpTV8ad1WZwzOoobZiaREOZnt0nVYMSVqKFvgBTgbhRnbqqUsnMRbtvnrpNSjpZSjpJS/tG87zEp5Sfm14eklGdJKdOklOlSyq+6/1a6gI3Ko22xhIrmVdSTV1HfziwEsD1/O9vztzu9TWyIH0U2KpBmFdXQ2GKyRgwBXDQhFqNJ8vXhEuu+FqOJA4XV7cxCrdfWubQ61huaeX1rTq9X+swprXObWQggxM8bX62m101DlrpRbZmSpJgUVfPQ4MBokvx2dSbeXoK/XTkJIQSJEQF2m1QNRhyVoT7X/PMK4GLgDPN2sXnfwMVOeQkLlgY0pyrqya+sb+co7gqxITpO1xhoMZra7c/Mby0gZ2FCfDAJYX6s398aPXT0dC2GZhNpbRzFFmJCdFQ3NFPf5Dip7H+ZhTz9+WEOFuq79R66g8kkyS13ryAQQphrLPWus7itf8DC+LgQfLUaVRAMEl7Zcpzdp6p46mcTrCbIpHB/cstU0xDAHPPPS21sl3h4Xp6lodJmMpkFi0aQVVxDWW1Tt+3csSF+mCSc7hANlHmqishAn3a1i4QQLJwQw3fHyqhuaAaU+kKAXY0AnJtKss2RDwVVvbe6KdYbMDSb3CoIQHHalvSmaaja0C5iyIKPVkNaQqjqJxgEHCrU84+vs7l4YiyL0uKs+5Mi/NEbWoZMCKmjMtSWXgRPSilvbLsBT/XO9DyEE40gIsCHAB8vvj9WBrjWsN4WsaG2+xJk5lWSPjy0U52ghRNjaTZKvs1SzEN786sJ0mkZEdH5gRrtos38SIkiCHqzocqJMveGjlqICXbNHOYuTtcY2jmK2zI5KYyDBdUYmgdPHcahRmOLkd+sziTEz4enfjah3ffRVoWBwYwrnjxbcZJr3D2RXqW+Avw6m1ssCKFEu1hWfB2zihOCE0gIdl7dLy6kc6ey6oZmjpfWtTMLWUhPCCU2RMe6/Ur00L78KtISQtFoOju1nSWsgRIOl11i0Qh6TxDkWARBD7KKbRFj9ov0RjxBU4uJstomm6YhgKlJYbSYpLUO1EBnqPUKaDGa+P3HB8gqruGvV04kPKB9YcMk8+Lr5BDxE9itBiaEGAOMB0I6+ASCUcI8BybNDdDS4NBZDIpqaEko6agRvHPFOy7dylanMou5J82GINBoBAvGx/DujlOU1zaSVVTDLefYruZhjaJxsEIurWmkql4xMxX0pkZQWoeft5fd1XR3iQ7W0dRioqq+mbAAz1YkPV3TOYegLZMtDuNTlcwY6Ti5sL/z+CcH2V9QzXvLz+zkGB+M1Da28KuVu9mcXco956Vw3tjoTmMsGsGp8qHhJ3D0V09F8QWE0t4/MBlY7vmpeYgG8wrOgWkIWv8R/Ly9iOjmQydYpyXAx6vdqt1ScXSSDQcwwEUTY2lqMfHixuO0mKTdcX4+XoT6eztsh5ldolTsDPTV2gxj9RQ5ZUqxOXeXyHZF+LkLa1axHUEQHuDDyMgAdg2CSqSbs0vZdbKSf397tK+n4nFK9AaufmU73x0r40+XT+Te+aNtjvPz8WJYkO+QMQ3Z1QiklP8D/ieEmGnO+h0cOKg82haLIBge7tfpgfbrL34NwPMXPu/wGkIIYkPbh5Duza9iVJTSacwWU5LCiAz05Z0fTgK0qzHUkZhgHcXV9qNoLP6B2SmR/JBT7nCu7uREWR0T4u3Pu7vEhCgaRrHewNjYYCeje4atrOKOTEkK4+vDJf2+L4Qj6hpbyC2vI8hXy4ubjnPu2GibZsvBQHZJDTe+9ROV9U28vnQq81KHORyfFOE/ZExDruiBtwkhrP8ZQogwIcSbHpyTZ3FSXsJCotlGaCt0NLM4k8ziTJdup2QAK6vx1oqj9u/tpRFcOCGaJqOJqCBfuytSy7UdtazMLq4hIsCHCfEhVNY7DzV1B00tJvIq6t1SbK4j1jITvRA5ZCuruCMZiWFU1Tdb61ENRLKKa5ASHl80nuggX36zOtNaYmEwse14GVe+vI0mo4nVt850KgRA8RMMlTITrgiCSVJKq0dMSlkJZHhuSh7GQeXRtrRqBD0rkRAX4mftXZxf2UBZbRPpiY5XXBdNiAUgLaFzZFFbYkL8HEYNHSmpYXR0kDVMtTf8BKcq6jFJ99UYaoslw7c3TEPFegPeXqKTE7Etlqio3AFsRz5cpOSXzBgZzjM/TyOntI6/fpHVx7NyL5/tK2TpmzuICdbx8R2zXNZWk8L9zaHQg08wdsQVQaARQliXsObuZK61nOqPuKgRJIT5MS42mJmjeuYIjAnRUVbbSFOLyVpxNN2O3d/C9ORwJsaHcMH4zk6sdtcO1lFWa7s0s8kkOVpSQ2pMEPGhZkHQC5FDraGj7o0YAiV+PzLQp1eyi0/rG81VXu0LYkvvioFsPjhUpCdYpyU+1I+zzohk2awRrNiWaw2dHuiU6A08sGYfkxJCWXPbLGuZeVdom1jqjPd/OsXBwupuz7OvcUUQ/B3YLoR4SgjxNEqnsr95dloexOojcCwIvL00rLtnNgvGx/TodnGhOqRU/iEtFUfHxAY5PEfrpeHTu87mqqnDHY5zVJq5oKqBuiYjo6ODiA/rTUGgOKiTbeQ+uIPo4N6psWQvmazdXIJ0+Gg1Azqy5HCRnrGxwVaB9+CFYxgZGcD9H+xFb2ju49n1nGe+PEKz0cRzV6UR4u9KG5VWrCGkTsxD9U0tPPTRfv72xZFuz7OvcaXW0P8BVwIlQDFwhZTybU9PzGM0VIKXL3h33+QzOmI0oyNsRxt0pG28f6adAnLdJcZBpzJL/kBqTCDDgnRoNaJXTEM5pXVEBPh0+UvnKkpSmefLTJToDQ79M6CE+yaG+w/YyBKjSXKkuKad493Px4u/X5VGsd7AE58c8uj9m40m/vF1Nves2uMRW/z+/GrW7MrnprOSrQ/1rpBkTSpzLOgPFOgxScUPUV0/MIWnSyYec9XQUsz5A0KIRCnlKY/OzFM4qTzqCq9e+qrLY+PM2cWnKuo5UFDNdWcmdfu+HYm1kadgwRI6mhIdhJdGqdPTGxpBTpl7awx1JDpEx55eSOIq0RuYk+q8CVLSABYEJ8vrqG8yMi6ufQRWRmIYv5p3Bv/69hgXjI/usVZsi7yKeu5etYc9p6rw0WpYv7+Y5eckc8fcMwjw7bnlWUrJk58dJDLQhzvPPaNb1wj19yZIp3VqGrLkBjUbJRsOl3DlFOfJpv0Np5+4uWT034E44DSQhFJWerxnp+YhnFQedTcxZo1g05HTnSqO9vza9stMZJfUEBeiI1inrMzjQ/16RSM4UVbH3NFu6CJnh5hgHRXmlpW+Wi+P3KPG0Exdk9GpRgCKHXnb8fIBGUJ6uEjRGsfZCMW969wUvs06zV3v7uGMYYEkRwaQHBnAiMgAkiP9OSMqqNta3+f7ivjdR/tAwr+WZDA9OZy/rM/ixY3HWbMrn4cvGsuitLgefZ6f7y/ip9xK/nzFRIJ03ZunEEIJIXUi6PfmV1t7lK8/UDw4BQFKXaEzgQ1SygwhxDzgOs9Oy4M0VDn1Dzjjlk9vAVzTDAJ9tQTptHybdRrArYIgSOdNoK/WZhTNkeIaUto0s4kP8+OH457NJagxNFNa00iym2sMtcXycD6tb3Rb05uOWJLJHOUQWEgK96eh2UhpTSPDXBjfnzhUVI1WIzhjWGfHvo9WwyvXT+HN73LJKavlYGE1XxwsxmguZ+6r1fD+rTO79P/c0GTkiU8PsuqnPDISQ3nhmgzr3/AfV6dz3ZmJPP7JIe5Zlcnb20/y+KLx3cpHMTQb+fO6LMbEBDn1szkjKTyAQ0WOK/fuzasibXgosSF+vPPjSWobWwh0g1bTm7hirG6WUpajRA9pzL0Ipnp4Xp6joaLHgiC7PJvs8myXx8eF+FHfZCQioH3FUXdgq0FNi9HEsdJaUmNaBUFCqB/FegPNHUpiu5PcMmXl5IkcAgvRvdCpzJVkMgtJke6pSVNV39Tr9uXDRTWMigpE521bs0oI8+exS8ex4sbpbLp/HllPXcjG++by5rKp+Pl48dLGYy7fK6tYz6X//o73d+Zxx9xRrL51ZidBPiUpnP/96iz+euVETpTVccVL2zheWtvl9/XGdycoqGrgsUvHtWso1R0SI/zJr6y3CsCOVNY1caqinkkJoSycGENTi8m66BtIuCIIqoQQgcAWYKUQ4p/AwA2TcFJ51BNYqpDaqjjaU2KCO7esPFlRT1OLqV17y/gwpSS2JyNucswRQ54IHbXQG53KLNd2FjUEbR2K3RcEUkqWvPYjFzy/2WHJEHdzqFDPWCcRbG3x9tKQHBnAuWOiuf7MJL4+XEKOCw/qusYWrnt9B9UNzbzzyxk8cOEYuwETGo3g6mmJrL9nNlovwXNfu77gAkWIv7jxGAvGRzNrVM/bnyeF+9NslBTa8a/tK1BCRtMSQpiSGMawIN92PUUGCq4IgsuAeuBe4AvgOErNoYGHlObKo70sCMx+Ak+k7tvSCCw9CFLbCIK4XsglyCmtQ4jWZDxPENMLTexLapxnFVtICPNHI3pWnGxTdimHi/ScrmnkphU7qW30fAZ4RV0TxXpDJ0exq9wwcwTeXhpe23rC6di3vj9BWW0jr1w/hbPOcO3hPCxYxy/PTubzfUUcKHA9Pt8SLvrwRWNdPscRznIJ9pkDFyYkhFiLRm48crpXsvjdiUNBIITwAj6TUpqklC1Syv9KKV8wm4oGHs0NYGzsVWcxtEb3OMso7u61O3ZBO1JSgxC0s/1ak8o86DA+UVZHfKifXVODOwj206Lz1nhUIyipNhCk0+Lv49zO66PVEBvi1yPT0Kubc4gJ1vHa9VPJLqnh7vf2dOpq524sGcXdrdkUFeTLlZMT+HB3PqU19sN5q+qbeGVLDuePjWZyYtcWYMvPGUmovzfPfOlafH5Pw0VtYbmOvezxvfnVjIoKsAZlLJwYg6HZxOYjpW65f2/hUBBIKY2ASQjh/gpifYGLWcXOSI9JJz0m3eXxM5LDGRsbTEYXvwiuEBOiwyShtLb1y3i0pJakcH/8fFofyBaNwJ6K6w5OeDh0FMwtK11oUNPQZOTP6w6z6cjpLtfat9ei0h6uRJbYY39+Ndtzyrnp7BGcPy6axxeN59us0zz9+eFuXc9VeioIAJbPTqbZaOL/tufaHfPy5uPUNrZw3wLX8m7aEqzz5vY5o9icXcqPToomGk2SJz49SESAD7/qZrioLWKDLUmDnf++Ukr2mnuGWJg+IpyIAB/WHSh22xx6A1dMQ7XAfiHEG0KIFyybpyfmEVysPOqM5y983mnl0bbMGBnB+ntmeySSINZGUpmlxlBbdN5eRAb6esw0JKXkRFmdRx3FFqKDdU5NQ5uzS3llSw7L3vqJ+f/YwsofT7pcTK3YhWSytiRF+He70fkrW44T5KtlyfREAK4/M4mbz05mxbZc3vreudmluxwq0jMsyJfIwO73jBgZFcj8sdG8/cNJm6aQEr2BFd/ncllaHGNiuidwls4aQXSwL3/78ohDgf7UZ4fYebKShy8aa12duwONRjA8zM+moC/WGyitaWzXSlbrpeGC8dF8e7hkQNUockUQfAQ8iuIs3tVmG3i4SSPoT8QEKyt9S0XOxhYjJ8rqOgkCUBzGnhIEpbWN1Da2eFwjgNZOZY44WFiNl0bwt8WT0Hlr+P3HBzjzz9/w1y+ynDpkS/SGLmkEieEBVNQ1dbkkQ15FPev2F/GLGYntYt0fumgs88dF89Rnh/jmcEmXrukqhwr13fYPtOXWOSOpqm9m9U95nY698M1RjCZpt+a/K+i8vbj7vBR2nay0G42z4vsTrNiWyy/PTvZIDH9SRIBN09/ePMV3MamD72/hhFjqmoxsPereek2e9B3ZFQRCiK8ApJT/BeLM/gHr5rEZeRIXK48647qPruO6j/pHKkXHMhM5pXUYTZLRMTYEQajOYz6CE6WKDTXZgxFDFmKCdZToGx2uEPcXVJMyLJCrpg7n0zvP5oPbZjJrVASvbD7O2X/daDeyw2SSnK5p7FJ3NUvxua6WSXjjuxN4aQQ3npXcbr+XRvDPa9IZHxfCXe/t6ZKz1BWaWkwcL611S0+HKUnhTEkK4/XvTrTza5wsr+P9n/K4ZvrwHtvrr5o6nBER/jzz5RFMHcI4vzlcwpOfHWL+uGi3OYg7khjuz6nyuk7/b/vyq9BqRKeEvJmjIgjx82b9AfdFD5XoDcz520ZW7+wscN2BI42gbXrozz1y997GTRpBvj6ffH2+GybUc8L8vfHRaqwrZGuNIVsaQaiiEXiiP21rn+LeMQ01tZiotBN3L6XkQEG1NRlJCMG0EeG8fN0UNt8/j6QIf17bmmPz3LK6Rowm6VLoqIXuNDqvrGvi/Z/yWJQWb/Ne/j5a3lg6lVA/b25fucutf7Ojp2toNkqbGcXd4ZZzRpJf2cD6Nnbx577ORusluPvclB5f39tLw73zR5NVXMMnewut+w8UVHPXe3sYHxfCP69J73HOgD2SIvypazJSXtfUbv++/GrGxAZ1Co7w9tIwf1w0Xx8qoaml505/KSUPrNlHXVMLU5M8Y81wJAgGXzdrFyuPDiSEEObmN4ogOFJcg1YjbJpo4kP9aGwxdfqHdgcnyurw0WqsTmlP4qi0BsDpmkbKapuYYMP0MTzcn6umDmf3qSqbxcROdyGr2EJrOWrXQ0jf+eEkDc1Guz2pQQmhvOWckeRVNDiMzOkqltIS7uryNn9sNCMjA3h1Sw5SSg4X6flkbyHLZiW7Ldv60klxjI0N5rmvs2lqMVFcbeCX//2JUD9vXl861aUIr+5i/fu2EfQmk+IottdKduGEGGoMLWw7bts81NhitPbFdsZ7O/LYnF3KQwvHeixHx5EgGCmE+EQI8Wmb19bNI7PxNA2VoPUDb88/rHoTpWWlYvLJLqlhZFSAzSbk8eZa7J4wD+WU1jEiwt9jq7K2RDvJJbCYUuyVJ7gsPQ4h4OM9BZ2OWYRLVwRBkM6biAAfl01DhmYj/92ey9zUqHbZ37awlAk5errrGbb2OFSoR+etcZs/R6MR3Dx7JPsLlAioZ788QqCvltvnjHLL9S33uH/BaE5V1PPW9ye4acVP1DUaeWPZtC79rbpDYrjyOZ1qI+hzy+uoMbSQlmD7f+zslEgCfbWs398+ekhKyZcHi5n/3BbO/utGth51HGZ6sryOpz8/xNlnRHK9GwtWdsSRILgMpdjcs21et90GHvW9n1XcG7TTCGxEDFnwZIOaE+aG9b1BjJMyEwcK9Ahhf8UbG+LHzJERrN1T0MnkYkkm60rUECiJR66ahj7aXUBZbZNDbcBCijkX5KjZ5OcODhfpSY0JdqvQvmJyPJGBPjyy9gDfZJ3mtjmj3F6KfF7qMKYmhfHn9VkcKanh37/I8HjvarD0LW+vEezLNzuK7WgEvlovzhs7jK8OFVt9J0dLarjhzR3c+vYuRRBHBHDzf3fa1RqMJsl9H+y1Bj1oPLjIsisIpJSbHW2uXFwIcaEQ4ogQ4pgQ4nc2jv9DCJFp3rKFEJ6tL9xQ6ZZkspkJM5mZMNMNE3IPMSF+lOgN1Da2kFfRYNM/AJ5LKmsxmjhVUU9ypOcdxQDDgnwRwr5p6EBhNaOiAh2WM/5ZRjy55fXWrnEWSqoNaAREBtpvUWmLpHDXQkhNJsnrW3OYGB/CzJHOu99FBfkSrNO6TSOQUnKoSM+4LpSWcAWdtxdLZ44gp7SOyEBfbjxrhFuvD4oZ9KGLxuDn7cUTi8Yz14W+w+7AV+tFbLCunSDYm1+FzltjFdS2WDghlsr6Zr4+VMITnx7kwn9uZW9eFY9fOo51d8/m3eUzSIrw55crdtrMk3h9aw4/5VbyxKLxHje5Oooa+lQIcakQopNYF0KMFEI8KYS4ycH5XsCLwEJgHLBECDGu7Rgp5b1SynQpZTrwL5RQVc/hpjpDfz7/z/z5/D+7YULuITZER7NRsuOE8s9kK2IIlKzcQF+t2zWCgqoGmo2yVxzFoDjjIgJ87ZqGDhZU2/QPtGXhhBh8tZpO5qFivYHIQF+0XWwelBgRQGF1g822oW35+nAJOWV13HLOSJfqTgkhSIkOcpsgKKo2UN3Q7DZHcVuun5lEXIiOBy5M9ZjNfkpSOHv/cIFb+3q4gqLxtZqG9uZVMTE+xOH/ydzUKPx9vLh95W5WbMvl6mnD2XjfXJadlYzWS0NEoC8rbz6TuFAdN674iV0nK6znHimu4e9fZbNgfDSXZ8R79L2BY9PQcmA2kCWE+EkIsU4I8a0QIgd4BdglpXzTwfnTgWNSyhwpZROwCsXEZI8lwHtdnH/XcEPl0f6IxUZqSWu3ZxoSQlgjh9yJJWLIk+WnOxIT4mvTNFRe20hhtcFp+eIgnTfzx0Xz6d7CdhVZS/SNXYoYspAU7o+UkO9E23ptSw4JYX4snOB6s5eUYYEcd5MgcEdGsT1C/X3Y9tB5PS797Axb/i9PkxQeYNX4mo0mDhbq7ZqFLOi8vVg6awSzUyL59M6z+dPlE4nokMAXFeTLu8vPJDpYx9I3fyIzr4qmFhP3vp9JsJ+WP10+sVf6XDgyDRVLKR+QUo5CCR99CvgNMEFKOV9K+T8n144H2ga95pv3dUIIkQQkA9/aOX6LEGKnEGJnaWkPani4SSO4cvWVXLn6yh5fx11Ysos3Z5fiq9U4LPoWH+b+BjXHzN3QeksjAIuDvLMgOFCoPOjGxzmvinJ5RjyV9c1syW79nyrRGxgW1A1B4EIuQXG1gZ0nK7l2RlKXNI4zhgVSXtdEeW3PI4cOmT+fMb1gWx9MJEX6U1bbRG1jC9klNTS2mNplFNvjwQvH8PYvZzhcmEQH63h3+QzCA3y4/o0feWDNXg4V6W0KDk/h0n+jlDJXSrldSpkppfREX75rgDXm2ka27v+qlHKqlHJqVFQ3u1+5sfJoeX055fX9p+6eRRDklteTEh3o0AkYF+relpWGZiMrtuUyNjaY8ICu2dV7gr0yE5aIIVeyZs8ZHUV4gA8ftTEPlegNxIR0/ctnqVJprzgZYI0QmetCC8y2WIoHHnODVnC4WE9ShP+Aa5zS1yRZIofK662O4jQnGkFXiA3x493lMwjWebM2s5DFUxK4wAMtQu3hSR2rAGirIyaY99niGjxtFmqqA1Nzr1ce7Q0iAn3Rmh/+9sxCFuJD/aluaHZbuvrrW3MoqGrg0UvG9mqrxphgHZX1zZ3quRwsrCYp4BF1YwAAGQBJREFUwp8QP+cRK95eGi6dFMuGQyXoDcq1Kuubie6GRhAV6Iu/j5fDyKGtR8uICvJljJOQ0Y64M4T0UKHeI/6BwY5V46uoY19+FSF+3tZ97iIhzJ9Vt5zJHXNH8dil45yf4EY8KQh+AlKEEMlCCB+Uh32n/AMhxBggDNjuwbkMymQyC14aYfUT2IsYshAf5r4qpCV6Ay9tOs4F49zTBKQrWDqVWRLALBwo0DPBBbOQhZ9lxNPYYuKLA8WtyWTd8BEIIZRSBHYih0wmyXfHypidEtllgRkXoiPAx6vHGkFtYwsnK+p7JeRysJHYJqksM6+aSQkhHln4DA/354ELx7i1cJ4rOBUE5sihLgsMKWULcCfwJUqz+9VSyoPmaKNFbYZeA6ySnqh70BZreYnBpxFAa2y9vYghC+4MIbU0Afn9xZ6p8eIIa6eyNuah6vpmTlXUd6nPbfrwUJIjA/h4d0G3cwgsJHWILGnLwUI9FXVNnJPSddOmEEpf4Z4KgiPFeqS03axexTHBOm/C/L05UlJDdkmNW81C/QFXDIVXA88LIT4E3pRSZrl6cSnlOmBdh32Pdfj9cVev1yPcWHn0vOTzenwNdxPjokZg6Zmc30ONYF9+FWt25XPrOSPd1gSkK9hKKjtYaMkodv1BJ4TgZ+nxPP9NNpmnlJyC7maqJkUEsPFIKSaT7JT8s8XsH3C1Q1dHRg0L5PtjPatmechSWsINVUeHIokRAWw4VILRJF1yFA8knK70pZTXARkoLSpXCCG2m6N43JuR4mncVHkU4NE5j/LonEd7fB13MiYmiLgQndVxbI+oQF+8vUSPNAIpJU9+esjtTUC6grXMRJvIoQNmQeBKxFBbfpYRh5Twprn+f3c1gsRwf6UOjg0n9tajpYyLDSYqqHtRICnDgijRN1Ld0P0G94cK9QTrtMR1w/SlooQI6w2Kby3NA21n+xJXo4b0wBqUXIBY4HJgtxDiLg/Ozb0Mwl4Ebbl97ii++s0cp3ZLjUYQG9KzXILP9xex82Qlv70gtddtmRaCdVr8vL3aPXQPFOiJD/XrcvRSUkQAU5LCKKo24KvVEOzXvYgaW8XJQGnevutkJbNHd9+PkuKGyKHDRUoPgt506g8mLH/f6GBfj9c36m1c8REsEkJ8DGwCvIHpUsqFQBrwW89Oz4001QHCLYJg4cqFLFy5sOdzciNaL43LIYHxoX7ddhYbmo38eV0WY2KCuHqaZxOHHCGE6NSg5kBhNeO7afb4mTl7MyZE1+0HZZKN4mQAP+SU02yU3fIPWEiJVgRBdxPL6ptaOFSkZ2IX/Ccq7bHk5ww2/wC4phFcCfxDSjlRSvmMlPI0gDmf4JcenZ07OetueKwctD1P0GhobqCh2XO9fz1NT5LK3vjuBAVVDTx26bheqTTqiOhgX6tpqLaxhRNldV1yFLflkomxeHuJHq304kJ1aDWik0aw9WgZOm8NU0d0fxGSEOaPr1bD0dPdKz63/Xg5TS0mzhndfWE01LH4wgabWQhccxY/Dlhb7Qgh/IBoc5LZN56amEfQeDkfMwSID/WjpMZAU4upS+n6JXoDL2481ifhoraICdax86Ri8jtcpETEdMVR3JawAB/uOS+lW1nFFrReGuJt9LfdcrSUM0dG4Kvt/v+fl0YwMiqw27kEm46U4uftxfTkwRk11xtMjA/hookxXDwxtq+n4nZceQp8ALRts2M071MZoMSH+iGl/eqdtjCaJI+uPdBn4aK2iA7RcdrcstJZDwJXuPPcFK7qobkrMdy/XYOa/Mp6ckrrmN0Ds5CFlGGBHC3puiCQUrIp+zRnndEzYTTU8fPx4qVrpzCiF0up9BauCAKtuWgcAObXvVdLQMXtWJLKXHUYG02S+z/Yy1eHSnjwwjF9Ei5qi5hgHU1GExV1TewvqGZYkG+PVvTuIMncl8CSFvOduYH5OSk916BShgVSUNVAXRezwnPK6siraGBOL5VtVhl4uCIIStsmgAkhLgN6FtA8wLlk9CVcMvqSvp5Gt+lKgxqTSfK7D/fx0Z4Cfjt/NDfPdt5Mpbdom1R2sEDfI23AXSSFB1BjaKHK3E95y9FSYoJ11npBPcHiMM4pdb0lJihmIYC5qn9AxQ6u+AhuA1YKIf4NCJSKojd4dFb9nPtm3dfXU+gRsaHKA9SZw1hKye/XHuCDXfncfV4Kd53X80bk7sRSCuJkeT1HT9ewYHx0H8+obf/ieoL9vPnuaBkXTohxS8jmGcMsNYdqmNiFhKZNR04zKiqA4Q6q0qoMbZwKAinlceBMIUSg+Xf3NU9V6RN8tV4MC/KloMp+gTQpJX/45CDv7TjF7XNHce/5/UsIQKtGsOnIaUwSxvcHjcBsNjtZXoeUEr2hxS3+AeXa/mg1oksO4/qmFn7MqeD6mb3byEVlYOFS4LkQ4mJgPKCzrGyklE96cF79mrkr5gKwadmmPp1HT4hz0KBGSslTnx3m/7afZPnsZB5YkNovk5CizC0rv806DfTMUewuLLHmp8rrOVlejxDdLyvREW8vpeF8VxzG24+X02Q0dbn0tcrQwqkgEEL8B/AH5gGvA4uBHR6el4qHiQ/zszYpaYuh2chf1mexYlsuy2aN4OGLere8dFfw9tIQGehLaU0jYf7e/aJ0gp+Pom2drKjnZHkdE+ND3NqnISU60ObfzR5q2KiKK7jiLJ4lpbwBqJRSPgHMBEZ7dloqnibBrBGYTEp0i5SSLw8WM/8fm61C4A+Xjuu3QsCCxTw0Id4zZYG7Q1KEPwcL9ew+VcVsN0QLteWMYUGcqqjv1IfBFmrY6P+3d+/hVtV1Hsffn44QNyOFMMcDQYL4mCk6hGKOQ14aZESngQd00ommCQZzRhpzSh9rTE2b6WYXsbAcHLOE8dIAmSaE1YRjQFGJeoywHnBQPN5vye07f6x1anM4l3X22eusc/b6vJ7nPGfd9t7fH6znfPfvsn4/yypLImgZbP6KpD8BdpLMN2R92CEHDGTHrj00v/wav37yRc77xk+Zd/N6BvZr4Ja/P47Lz3xbr/nD2pGDKhJBbzHqwME8vO0Fdu/p3rQSbRk3Ygh7Ah5r7nzkkIeNWlZZ+giWS3oj8BngZ0AAN+QaleWuZQjppXc8yOqm7Qzu38Dl04/g3OO7tp5u0VqWlezKYjR5axk5NLh/A8eMqu0khy3DUH+9/aVOF5jxsFHLqsNEkC5IsyoingNul7QCGBARz/dIdL3UrLfNKjqEbmt5qGzVI09yzqRRXHTaYT22UHYtHTw0KUe1k83loSURTD50WJem8MhizPDBvE6w6cnO5xzysFHLqsNEEBF7JF1Hsh4BEfEa8FpHrymD899xftEhdNv4g/bnE2ccwaQxB/aqZpWumnFsYy7rx3bH6HQIaa2GjVYa0K+BtwwbzKanOh459OqO3Tzw2DOcd7yHjVrnsjQNrZI0A7gj9+Uk+4hXdibj7wf16z1/fLpKEn934piiw+i2Nw8dwLm97I/dUY1D+cLsozn9yHy60sZmmHPo/s3N7NjlYaOWTZZ66zySSeZek/SCpBclZR+/Voem3TKNabdMKzoM66Uk8Z5jGhnQL5+ROuNGDOGx5pfZuXtPu9esfsTDRi27LEtV7h8Rr4uI/hHxhnS/9zTImpXM2BFD2LUn+N3TbY8c8rBR66osD5Sd1NbxiPhR7cMxs86Ma5lz6MmX/jD/UKWWYaNzTzq0p0OzPipLH8HFFdsDgEnAeuDkXCIysw4dOiLpjG5v/WIPG7WuyjLp3PTKfUkjgWtzi8jMOjSo/340HjCw3cnnPGzUuirbaud72wr0jiWqCjJnwpyiQ7CSGzdi72UrI4KHt73I6qbtHjZqXZalj+DLJE8TQ9K5PIHkCePSciKwoo0dMYSf/OZp7tn4BPc1bWf1I0/xxAvJbDBHNQ7lbz3ttHVBlhrBuortXcC3I+InOcXTJzS/kizQNnxQ8Qu4WzmNG7E/O3btYd7N6xny+v04cexwTj58BFPGv4kRbyh+FlbrW7IkgtuA30fEbgBJDZIGRUT7q5rUuZlLZwJ9ez0C69umHXUwT7+8g6MbhzJx9IE1n8rCyiXL3bMKGFixPxBYmeXNJU2V1CRpk6SPtXPNLEkPSdoo6VtZ3tes7Ia8fj/mTzmUE8YOdxKwbstSIxhQuTxlRLwkqdPhCJIagOuA00g6mNdKWhYRD1VcMw64BHhnRDwryfPlmpn1sCxfJV6WdGzLjqQ/BTpe9TwxCdgUEZsjYgdwK3BWq2s+CFwXEc8CRMT2bGGbmVmtZKkRLAD+S9L/AQLeDMzO8LpDgC0V+1uB41pdcxiApJ8ADcDlEXF36zeSNBeYCzBq1KgMH21mZllleaBsraTDgfHpoaaI2FnDzx8HTAEagR9Jenu6/kFlDIuARQATJ04sfAbU+RPnFx2CmVnNZHmO4EPALRHxYLp/gKRzImJhJy99HBhZsd+YHqu0FXggTSyPSXqUJDGszVqAIsw+MkuFyMysb8jSR/DBym/oaXv+BzO8bi0wTtIYSf2Bs4Flra75DkltAEnDSZqKNmd470JteX4LW57f0vmFZmZ9QJY+ggZJalmUJh0N1L+zF0XELkkXAPeQtP/fGBEbJV0BrIuIZem5d0t6CNgNXBwRT1dbmJ5y3p3nAX6OwMzqQ5ZEcDewRNLX0v156bFORcRdwF2tjn2iYjuAf05/zMysAFkSwUdJRuy09JDeC9yQW0RmZtajsqxQticivhoRMyNiJvAQ8OX8QzMzs56QaRpqSccA5wCzgMeAO/IMyszMek67iUDSYSR//M8BmoElgCLiXT0UW6910eSLig7BzKxmOqoRPAL8GDgjIjYBSPpwj0TVy00fP73zi8zM+oiO+gj+GtgGrJZ0g6RTSKaYKL2m5iaampuKDsPMrCbaTQQR8Z2IOBs4HFhNMufQCEnXS3p3TwXYG81bMY95K+YVHYaZWU1kGTX0ckR8K13EvhH4OcmQUjMzqwNdWtEiIp6NiEURcUpeAZmZWc/y0kZmZiXnRGBmVnKZHiizvV120mVFh2BmVjNOBFU49a2nFh2CmVnNuGmoChue2MCGJzYUHYaZWU24RlCFBXcvALwegZnVB9cIzMxKzonAzKzknAjMzErOicDMrOTcWVyFq0+5uugQzMxqxomgCieMPKHoEMzMasZNQ1VYs2UNa7asKToMM7OacI2gCpeuuhTwcwRmVh9cIzAzKzknAjOzknMiMDMrOScCM7OSy7WzWNJU4ItAA/D1iPh0q/NzgM8Aj6eHvhIRX88zplq4duq1RYdgZlYzuSUCSQ3AdcBpwFZgraRlEfFQq0uXRMQFecWRhwlvnlB0CGZmNZNn09AkYFNEbI6IHcCtwFk5fl6PWbl5JSs3ryw6DDOzmsizaegQYEvF/lbguDaumyHpJOBR4MMRsaWNa/6oqQmmTNn72KxZcP758MorMG3avq+ZMyf5aW6GmTP3PT9/PsyeDVu2wHnn7Xv+ootg+vTks+fN46oJyaI0p25IawaXXQanngobNsCCBfu+/uqr4YQTYM0auPTSfc9fey1MmAArV8JVV+17/mtfg/HjYfly+Nzn9j1/880wciQsWQLXX7/v+dtug+HDYfHi5Ke1u+6CQYNg4UJYunTf8/fdl/z+7GdhxYq9zw0cCN/7XrJ95ZWwatXe54cNg9tvT7YvuQTuv3/v842N8M1vJtsLFiT/hpUOOwwWLUq2586FRx/d+/yECcm/H8C558LWrXufnzwZrrkm2Z4xA55+eu/zp5wCH/94sn366fDqq3ufP+MM+MhHku3W9x30+L23D997ybbvvX3Pd3bvVSi6s3g5MDoijgLuBW5q6yJJcyWtk7Ru586dPRqgmVm9U0Tk88bSZODyiPiLdP8SgIi4pp3rG4BnImJoR+87ceLEWLduXa3D7ZIpi6cAfrLYzPoOSesjYmJb5/KsEawFxkkaI6k/cDawrFVgB1fsngk8nGM8ZmbWhtz6CCJil6QLgHtIho/eGBEbJV0BrIuIZcA/SToT2AU8A8zJKx4zM2tbbk1DeekNTUNNzU0AjB8+vtA4zMyy6qhpyLOPVsEJwMzqSdGjhvqk5U3LWd60vOgwzMxqwjWCKnzu/mQ89fTx0wuOxMys+1wjMDMrOScCM7OScyIwMys5JwIzs5JzZ3EVbn7PzUWHYGZWM04EVRg5dGTRIZiZ1Yybhqqw5MElLHlwSdFhmJnVhGsEVbh+XTLv+uwjZxcciZlZ97lGYGZWck4EZmYl50RgZlZyTgRmZiXnzuIq3DbrtqJDMDOrGSeCKgwfNLzoEMzMasZNQ1VYvGExizcsLjoMM7OacCKoghOBmdUTJwIzs5JzIjAzKzknAjOzknMiMDMrOQ8frcJd772r6BDMzGrGiaAKg/oNKjoEM7OacdNQFRauXcjCtQuLDsPMrCacCKqwdONSlm5cWnQYZmY14URgZlZyuSYCSVMlNUnaJOljHVw3Q1JImphnPGZmtq/cEoGkBuA64HTgCOAcSUe0cd3+wIXAA3nFYmZm7cuzRjAJ2BQRmyNiB3ArcFYb110J/Bvw+xxjMTOzduQ5fPQQYEvF/lbguMoLJB0LjIyI70q6uL03kjQXmJvuviSpqcqYhgPNVb52H3q/avVWeatpufuYspbd5S6XLOV+S3snCnuOQNLrgM8Dczq7NiIWAYtq8JnrIqJ0/RBlLTeUt+wud7l0t9x5Ng09Doys2G9Mj7XYHzgSuE/Sb4HjgWXuMDYz61l5JoK1wDhJYyT1B84GlrWcjIjnI2J4RIyOiNHA/wJnRsS6HGMyM7NWcksEEbELuAC4B3gYWBoRGyVdIenMvD63E91uXuqjylpuKG/ZXe5y6Va5FRG1CsTMzPogP1lsZlZyTgRmZiVXmkSQdbqLvk7SjZK2S3qw4tiBku6V9Ov09wFFxpgHSSMlrZb0kKSNki5Mj9d12SUNkPRTSb9Iy/3J9PgYSQ+k9/uSdMBG3ZHUIOnnklak+3Vfbkm/lfQrSRskrUuPdes+L0UiyDrdRZ1YDExtdexjwKqIGAesSvfrzS7goog4gmQo8ofS/+N6L/trwMkRcTQwAZgq6XiSp/W/EBFjgWeBDxQYY54uJBmM0qIs5X5XREyoeHagW/d5KRIB2ae76PMi4kfAM60OnwXclG7fBPxVjwbVAyJiW0T8LN1+keSPwyHUedkj8VK62y/9CeBk4Lb0eN2VG0BSI/CXwNfTfVGCcrejW/d5WRJBW9NdHFJQLEU4KCK2pdtPAAcVGUzeJI0GjiGZyLDuy542j2wAtgP3Ar8BnkuHcEP93u/XAv8C7En3h1GOcgfwfUnr0+l3oJv3uZeqLJmICEl1O2ZY0hDgdmBBRLyQfElM1GvZI2I3MEHSG4E7gcMLDil3ks4AtkfEeklTio6nh50YEY9LGgHcK+mRypPV3OdlqRF0Nt1FvXtS0sEA6e/tBceTC0n9SJLALRFxR3q4FGUHiIjngNXAZOCNklq+6NXj/f5O4Mx0eppbSZqEvkj9l5uIeDz9vZ0k8U+im/d5WRJBh9NdlMAy4H3p9vuA/y4wllyk7cPfAB6OiM9XnKrrskt6U1oTQNJA4DSS/pHVwMz0srord0RcEhGN6fQ0ZwM/iIj3UuflljQ4XcMFSYOBdwMP0s37vDRPFkuaRtKm2ADcGBGfKjikXEj6NjCFZFraJ4F/Bb4DLAVGAb8DZkVE6w7lPk3SicCPgV/xxzbjS0n6Ceq27JKOIukcbCD5Yrc0Iq6Q9FaSb8oHAj8Hzo2I14qLND9p09BHIuKMei93Wr470939gG9FxKckDaMb93lpEoGZmbWtLE1DZmbWDicCM7OScyIwMys5JwIzs5JzIjAzKzknAis1SbvTWRxbfmo2KZ2k0ZWzwGa4frCklen2/1Q8GGWWK99oVnavRsSEooNITQbuT6cQfrlizhyzXLlGYNaGdM73f0/nff+ppLHp8dGSfiDpl5JWSRqVHj9I0p3pugC/kHRC+lYNkm5I1wr4fvr0b+vPOjSdNO6bwN8A64Gj0xrKiB4qspWYE4GV3cBWTUOzK849HxFvB75C8lQ6wJeBmyLiKOAW4Evp8S8BP0zXBTgW2JgeHwdcFxFvA54DZrQOICJ+k9ZK1pPMG3MT8IF0vvm6nRvJeg8/WWylJumliBjSxvHfkiz4sjmdzO6JiBgmqRk4OCJ2pse3RcRwSU8BjZXTGaTTYd+bLhaCpI8C/SLiqnZiWRsR75B0O3BhRGytcXHN2uQagVn7op3trqic52Y3bfTLSfpq2qk8Lm0imgqskPThKj/TrEucCMzaN7vi9/3p9hqS2S4B3ksy0R0kywPOhz8sFDM064dExD8AnwSuJFlZ6rtps9AXuhe+WTYeNWRlNzD9Ft7i7ohoGUJ6gKRfknyrPyc99o/Af0i6GHgKeH96/EJgkaQPkHzznw9sI7s/B/4T+DPgh1WVxKxK7iMwa0PaRzAxIpqLjsUsb24aMjMrOdcIzMxKzjUCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzkvt/6/zQbdHRS14AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"h9Qp129rNV3U"},"source":["# Milestone 5\n","## Instructor-led Discussion: Model Evaluation"]},{"cell_type":"markdown","metadata":{"id":"wwERVb37ylko"},"source":["## Activity 5a. How did we do on pneumonia prediction? "]},{"cell_type":"markdown","metadata":{"id":"sXyQLXigDbtg"},"source":["\n","\n","### Exercise (Coding) "]},{"cell_type":"markdown","metadata":{"id":"hBbSwkgVj7gS"},"source":["Set your best model to the one you have trained (e.g., the transfer learning model)."]},{"cell_type":"code","metadata":{"id":"TmjOJCGDjsMk","executionInfo":{"status":"ok","timestamp":1605382686080,"user_tz":480,"elapsed":350,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["best_model = transfer ## Change this if another model did better!"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UBhDGS02VGHa"},"source":["As we learned last week, total accuracy does not reflect all that we want to know about a model's performance. It's just one metric out of many possible metrics for evaluating models. \n","\n","In the case of pneumonia prediction, we may be more interested in other quantities, such as 'how accurate were we on the pneumonia category?' or 'how accurate were we on the normal category?' or 'how much of pneumonia were confused for normal?' or vice versa. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"T_GjNUEBMSke"},"source":["Our metrics for classification can be described in terms of a 'confusion matrix', shown below. \n","\n","![Confusion Matrix](https://cdn-images-1.medium.com/max/1600/1*Z54JgbS4DUwWSknhDCvNTQ.png)\n","\n","In a confusion matrix, we think in terms of 'actual' and 'predicted values'. If we take Pneumonia = 1/Positive and Normal = 0/Negative, then...\n","\n","* True positive: True pneumonia: Pneumonia predicted as pneumonia\n","* True negative: True normal: Normal predicted as normal\n","* False positive: False pneumonia: Normal mistaken as pneumonia\n","* False negative: False normal: Pneumonia mistaken as normal\n"]},{"cell_type":"markdown","metadata":{"id":"BL0ns-b9GBym"},"source":["The `sklearn` package makes calculating confusion matrices very quick! Its `metrics` submodule actually comes with a `confusion_matrix` tool. Let's start by grabbing that."]},{"cell_type":"code","metadata":{"id":"f2E5299cNEcp","executionInfo":{"status":"ok","timestamp":1605382688060,"user_tz":480,"elapsed":373,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["from sklearn.metrics import accuracy_score, confusion_matrix"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bvFawPv1NIyy"},"source":["To use `confusion_matrix`, we need:\n","* `labels`: the labels of the data (1 - PNEUMONIA or 0 - NORMAL)\n","* `predictions`: what our model thinks the labels are\n","\n","To get `predictions`, we have to give our model `test_labels`, our `test_data`, and ask it to give us `predictions`. We'll do that with \n","\n","```\n"]},{"cell_type":"code","metadata":{"id":"-cLkk9eJkI3I","executionInfo":{"status":"ok","timestamp":1605382690602,"user_tz":480,"elapsed":778,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"15a652fb-22b9-4e52-c268-23babf2c6370","colab":{"base_uri":"https://localhost:8080/"}},"source":["predictions = best_model.predict_classes(test_data)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-11-bde20af3a3d4>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n","Instructions for updating:\n","Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ImWhImiQxnye"},"source":["First, use `accuracy_score` to get our accuracy"]},{"cell_type":"code","metadata":{"id":"Rvlm2oLCxq52","executionInfo":{"status":"ok","timestamp":1605382693195,"user_tz":480,"elapsed":402,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"d02859f4-659d-43f0-e9e4-b4aa8e017101","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Accuracy is %d %%'%(accuracy_score(test_labels, predictions)*100.0))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Accuracy is 72 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XcFGwTMDkCAp"},"source":["Now let's get our confusion matrix, and split it out into true positive, true negative, false positive, and false negative!"]},{"cell_type":"code","metadata":{"id":"O7omQvlbkSTn","executionInfo":{"status":"ok","timestamp":1605382698437,"user_tz":480,"elapsed":392,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"549a2c55-bc6f-48e3-f0f2-61824cdb3359","colab":{"base_uri":"https://localhost:8080/"}},"source":["confusion = confusion_matrix(test_labels, predictions)\n","print(confusion)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[ 90 110]\n"," [  2 198]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K17HWY9Iw3gA","executionInfo":{"status":"ok","timestamp":1605382700313,"user_tz":480,"elapsed":368,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["tp  = confusion[1][1]\n","tn  = confusion[0][0] \n","fp = confusion[0][1]\n","fn = confusion[1][0]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3kJwV4bw4lc","executionInfo":{"status":"ok","timestamp":1605382701795,"user_tz":480,"elapsed":376,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"0ebb939a-fa0c-4984-ef8f-e91fcb640f47","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('True positive: %d'%tp)\n","print('True negative: %d'%tn)\n","print('False positive: %d'%fp)\n","print('False negative: %d'%fn)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["True positive: 198\n","True negative: 90\n","False positive: 110\n","False negative: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eKlghw6_krXL"},"source":["We can visualize the confusion matrix with seaborn to make it easier for our eyes..."]},{"cell_type":"code","metadata":{"id":"Q0Cp60eokseD","executionInfo":{"status":"ok","timestamp":1605382705204,"user_tz":480,"elapsed":394,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}}},"source":["# grab our plotting package\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_Jwv2-OktLb","executionInfo":{"status":"ok","timestamp":1605382707135,"user_tz":480,"elapsed":547,"user":{"displayName":"Kiran Mitra","photoUrl":"","userId":"03214185584383348824"}},"outputId":"ca54c8d6-e62a-4531-9fcb-d3191ec466b0","colab":{"base_uri":"https://localhost:8080/","height":279}},"source":["sns.heatmap(confusion, annot = True, fmt = 'd', cbar_kws={'label':'count'});\n","plt.ylabel('Actual');\n","plt.xlabel('Predicted');"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"mdnF7l8_khHU"},"source":["## Instructor-Led Discussion: Comparing False Postives and False Negatives"]},{"cell_type":"markdown","metadata":{"id":"r8Tt6kTRkTvm"},"source":["**Now that we have our confusion matrix, let's take a step back and discuss**\n","\n","What did our model confuse more? \n","* PNEUMONIA for NORMAL or...\n","* NORMAL for PNEUMONIA\n","\n","Why do you think it might have confused one for the other? \n","\n","**Discuss with your instructor what you got and also...**\n","\n","What is more problematic? False positives or False negatives? \n","\n","Which of these metrics do we want to keep low? \n"]},{"cell_type":"markdown","metadata":{"id":"u8KmugJ_N9BQ"},"source":["# Fin!\n"]},{"cell_type":"markdown","metadata":{"id":"RV85QOOGQ2xm"},"source":["To recap, we built neural network models to see if we can do better than our simple logistic regression. It turns out that we can! And, also, by introducing convolutions to our networks (making the convolutional neural networks), we can improve by quite a lot. Finally, we employed pretrained 'expert' models to boost our performance even further.\n","\n","In the next section, we'll test out our models on actual field data!"]},{"cell_type":"markdown","metadata":{"id":"14rKID6MOo4N"},"source":["![](https://storage.googleapis.com/kaggle-competitions/kaggle/10338/logos/header.png)"]}]}